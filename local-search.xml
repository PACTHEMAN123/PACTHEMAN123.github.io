<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>运输层</title>
    <link href="/2024/09/12/%E8%BF%90%E8%BE%93%E5%B1%82/"/>
    <url>/2024/09/12/%E8%BF%90%E8%BE%93%E5%B1%82/</url>
    
    <content type="html"><![CDATA[<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>运输层负责将应用层的报文(message)，切分为多份并分别打包成<strong>报文段</strong>(segment)，然后传递给网路层。TCP和UDP即为运输层协议。</p><p>网络层协议为<strong>IP</strong>，服务方式为<strong>尽力而为</strong>，但不保证任何东西。</p><h2 id="多路"><a href="#多路" class="headerlink" title="多路"></a>多路</h2><p>由于一台主机上会有多个进程使用socket，所以要思考怎么实现正确的包装和交付。</p><h3 id="多路分解"><a href="#多路分解" class="headerlink" title="多路分解"></a>多路分解</h3><p>segment中有几个字段，接收端的运输层检查这些字段，识别出socket并将数据交付到达该socket。</p><h3 id="多路复用"><a href="#多路复用" class="headerlink" title="多路复用"></a>多路复用</h3><p>从主机的不同socket收集数据块，并为每个数据块封装上首部的信息，生成segment，再将其传递到网络层。</p><h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p>segment：</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs haskell">&lt;-------------------32bit--------------------&gt;[source_port_number | destination_port_number]<br>[other_header]<br>[<span class="hljs-class"><span class="hljs-keyword">data</span>]</span><br></code></pre></td></tr></table></figure><h2 id="UDP"><a href="#UDP" class="headerlink" title="UDP"></a>UDP</h2><p>为什么会选择udp？</p><ul><li>因为udp本身对数据没什么控制，与tcp不同。应用层可以更精细地控制</li><li>无需连接时间</li><li>无连接状态</li><li>首部开销小</li></ul><p>像视频通话、电话这种可以容忍丢包的应用，使用udp会更合适</p><p>udp的segment：</p><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs elm">&lt;-<span class="hljs-comment">--------32bits---------&gt;</span><br>[source_<span class="hljs-keyword">port</span> | desti_port]<br>[  length    |  checksum ]<br>[         data           ]<br></code></pre></td></tr></table></figure><p>通过校验和(checksum)，udp在运输层提供差错检测，但无法恢复差错，只能丢弃问题的segment并发出警告。</p><h2 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h2><p>可以先去看看后面的可靠数据传输原理。</p><p>客户与服务器的TCP连接需要<strong>三次握手</strong>(three-way handshake)。用户通过socket将数据传递，接着数据被TCP控制，存到<strong>发送缓存</strong>(send buffer)中。</p><h3 id="TCP报文结构"><a href="#TCP报文结构" class="headerlink" title="TCP报文结构"></a>TCP报文结构</h3><p>其报文结构如下：</p><p><img src="/images/Pasted_image_20240905153554_1.png"></p><ul><li>Sequence number 即为segment的序列号</li><li>acknowledgment number 即为segment的确认号<blockquote><p>主机A填充进segment的确认号是主机A期望从主机B收到的下一字节的序号。</p></blockquote></li><li>Header length 用来表示报文头部的长度，当 Options 为空时，长度为20。</li><li>Flag field 包含6个bit。其中 ACK bit 表示应答客户端是否成功接收，RST，SYN，FIN 用于连接设置。</li><li>Receive window 用于流控制。</li></ul><h3 id="传输机制"><a href="#传输机制" class="headerlink" title="传输机制"></a>传输机制</h3><p>TCP采用超时重传机制。需要有往返时间估计的方法。</p><p><strong>RTT</strong>：TCP会在某个时刻通过发送样本RTT来测量往返时间。对于一个新测出来的RTT，会通过加权平均以前RTT的估计值和现在的RTT来更新现在RTT的估计值，再用DevRTT计算出超时间隔。</p><p>除了rbt3.0实现的基本功能外，大部分TCP还会进行以下的修改：</p><ul><li><strong>超时间隔加倍</strong>：实现了一定程度的拥塞控制。当发生超时时，有可能是路径上有过多的packet，而此时按照原来的超时间隔重发，可能会加剧拥塞</li><li><strong>快速重传</strong>：当接收方收到一个序号大于预期的segment，说明发生丢包，接收方会向发送方产生一个<strong>冗余ACK</strong>(duplicate ACK)。如果发送方收到相同数据的3个冗余ACK，会将它作为丢包的指示，执行快速重传。</li></ul><p>TCP还提供<strong>流量控制服务</strong>(flow-control service)，注意其与拥塞控制(congestion control)不同。前者本质是一个速度匹配服务，即使发送方的发送速率与接收方的读取速率相同。后者是因为ip网络的拥塞，而遏制发送方。</p><h3 id="TCP三次握手具体实现"><a href="#TCP三次握手具体实现" class="headerlink" title="TCP三次握手具体实现"></a>TCP三次握手具体实现</h3><ul><li><strong>第一步</strong>：发送SYN segment，在首部的SYN比特被置为1，序号字段为client_isn（客户随机选择的初始序号）。</li><li><strong>第二步</strong>：服务器收到SYN sesgment，为该tcp连接分配tcp缓存和变量（可能导致<strong>洪泛攻击</strong>），向客户端发送允许连接的SYNACK segment，该segment的SYN bit被设为1，确认号字段被设为client_isn+1，序号字段被设为server_isn。</li><li><strong>第三步</strong>：客户收到SYNACK segment，为该连接分配缓存和变量，发送segment，其确认字段被设为server_isn+1，SYN bit设为0，并且可以负载需要传输的数据。</li></ul><h3 id="TCP结束连接"><a href="#TCP结束连接" class="headerlink" title="TCP结束连接"></a>TCP结束连接</h3><p>当客户进程发出关闭连接的命令，用户的TCP发出一个FIN bit为1的segment，服务器接收到后发送ACK，接着也发送一个FIN bit为1的segment，最后客户接收并发送ACK，即完成全部连接资源的释放。</p><h3 id="TCP拥塞控制"><a href="#TCP拥塞控制" class="headerlink" title="TCP拥塞控制"></a>TCP拥塞控制</h3><p>TCP的拥塞控制机制需要额外跟踪一个变量，即<strong>拥塞窗口</strong>，用cwnd表示。假设TCP接收缓存足够大，即不会出现接收窗口大小限制发送速率，只考虑cwnd的限制。此时发送速率为<code>cwnd/RTT byte/s</code></p><p>TCP感知出现拥塞：出现超时&#x2F;收到3个冗余ACK</p><h3 id="TCP拥塞控制算法"><a href="#TCP拥塞控制算法" class="headerlink" title="TCP拥塞控制算法"></a>TCP拥塞控制算法</h3><h4 id="慢启动"><a href="#慢启动" class="headerlink" title="慢启动"></a>慢启动</h4><p>TCP连接开始时，cwnd的值设为一个MSS，即发送速率为<code>MSS/RTT</code>，每当传输的segment都被确认，cwnd的大小加一倍。所以其实传输速率为指数增长，并不慢！</p><p>如果存在超时导致的丢包，则发送方将cwnd设为1并重新开始，将<strong>慢启动阈值</strong>(ssthresh)设为开始拥塞时的cwnd的一半。</p><p>当重新启动时，可能超过&#x2F;到达ssthresh，会结束慢启动模式，转到<strong>拥塞避免模式</strong>，更谨慎地增加cwnd</p><p>如果检测到3个冗余ACK，TCP执行快速重传并进入<strong>快速恢复模式</strong>。</p><h4 id="拥塞避免模式"><a href="#拥塞避免模式" class="headerlink" title="拥塞避免模式"></a>拥塞避免模式</h4><p>每个RTT只将cwnd的值加一个MSS，实现线性增长。结束增长和慢启动一样。不同的是，检测到3个冗余时，cwnd变为一半，将ssthresh记录为cwnd值的一半。</p><h4 id="快速恢复"><a href="#快速恢复" class="headerlink" title="快速恢复"></a>快速恢复</h4><p>对于引起TCP进入快速恢复状态的缺失segment，对于每个冗余ACKcwnd的值增加一个MSS。出现超时则和慢启动和拥塞避免一样。</p><h2 id="可靠数据传输原理"><a href="#可靠数据传输原理" class="headerlink" title="可靠数据传输原理"></a>可靠数据传输原理</h2><h3 id="构造可靠数据传输协议"><a href="#构造可靠数据传输协议" class="headerlink" title="构造可靠数据传输协议"></a>构造可靠数据传输协议</h3><p>这里的实现比较复杂，通过rdt(reliable data transfer)协议3.0来体会各个部分的作用。注意这里使用状态机 + 伪代码的方法来描述。</p><p><code>rdt3.0</code> 是一个用于可靠数据传输的协议，主要应对 <strong>丢包</strong> 和 <strong>比特错误</strong> 的问题。它引入了超时机制、序列号和确认（ACK）机制来确保可靠性，基于 <code>rdt2.x</code> 的基础，增加了对丢包的处理。</p><p>以下是 <code>rdt3.0</code> 的伪代码描述，分为发送方和接收方。</p><h4 id="发送方的伪代码"><a href="#发送方的伪代码" class="headerlink" title="发送方的伪代码"></a>发送方的伪代码</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">state: WAIT_FOR_CALL_FROM_ABOVE<br><br>while true:<br>    if event == from_upper_layer:   // 从上层接收到数据<br>        create_packet(data, seq_num)   // 创建数据包，包含数据和序列号<br>        send(packet)   // 发送数据包<br>        start_timer()   // 开始定时器<br>        state = WAIT_FOR_ACK<br><br>state: WAIT_FOR_ACK<br><br>while true:<br>    if event == timeout:   // 超时未收到 ACK<br>        resend(packet)   // 重新发送数据包<br>        start_timer()   // 重启定时器<br>    <br>    if event == receive_ACK and is_corrupt(ACK) == false:<br>        if ack_seq_num == seq_num:   // 收到正确的 ACK<br>            stop_timer()<br>            seq_num = (seq_num + 1) % 2   // 切换序列号<br>            state = WAIT_FOR_CALL_FROM_ABOVE   // 返回等待上层调用状态<br></code></pre></td></tr></table></figure><h4 id="接收方的伪代码"><a href="#接收方的伪代码" class="headerlink" title="接收方的伪代码"></a>接收方的伪代码</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">state: WAIT_FOR_0_FROM_BELOW<br><br>while true:<br>    if event == receive_packet and is_corrupt(packet) == false:<br>        if packet.seq_num == 0:   // 收到序列号为 0 且未损坏的数据包<br>            deliver_data(packet.data)   // 传递数据到上层<br>            send_ACK(0)   // 发送 ACK 0<br>            state = WAIT_FOR_1_FROM_BELOW   // 切换到等待序列号 1 的状态<br>        else:<br>            send_ACK(1)   // 序列号不匹配，重复发送 ACK 1 表示之前已经收到过该包<br><br>    if event == receive_packet and is_corrupt(packet) == true:<br>        // 数据包损坏，忽略不做处理（自动依赖发送方超时重传）<br><br>state: WAIT_FOR_1_FROM_BELOW<br><br>while true:<br>    if event == receive_packet and is_corrupt(packet) == false:<br>        if packet.seq_num == 1:   // 收到序列号为 1 且未损坏的数据包<br>            deliver_data(packet.data)   // 传递数据到上层<br>            send_ACK(1)   // 发送 ACK 1<br>            state = WAIT_FOR_0_FROM_BELOW   // 切换到等待序列号 0 的状态<br>        else:<br>            send_ACK(0)   // 序列号不匹配，重复发送 ACK 0 表示之前已经收到过该包<br><br>    if event == receive_packet and is_corrupt(packet) == true:<br>        // 数据包损坏，忽略不做处理（自动依赖发送方超时重传）<br></code></pre></td></tr></table></figure><h4 id="关键机制"><a href="#关键机制" class="headerlink" title="关键机制"></a>关键机制</h4><ul><li><strong>序列号</strong>: 发送方和接收方使用 0 和 1 两个序列号来区分重复数据包。</li><li><strong>ACK（确认）</strong>: 接收方向发送方发送 ACK，表明接收到的数据包是正确的。</li><li><strong>超时重传</strong>: 发送方在一定时间内未收到 ACK 时，会重传数据包。</li></ul><h3 id="流水线可靠数据传输协议"><a href="#流水线可靠数据传输协议" class="headerlink" title="流水线可靠数据传输协议"></a>流水线可靠数据传输协议</h3><p>rdt3.0本质为停等协议，我们希望在等一个packet的ACK时，可以同时发送其他packet，可以看作是将packet都填充到一个流水线上。实现需要增加以下机制：</p><ul><li>增加序号范围：显然之前的0和1是不够的，每个输送的packet都需要有一个唯一的序号</li><li>发送方缓存已发送但未确认的packet</li><li>选择处理丢包&#x2F;损失的方法：<strong>GBN</strong>(Go-Back-N)，<strong>SR</strong>(Seletive Repeat)</li></ul><h2 id="拥塞控制原理"><a href="#拥塞控制原理" class="headerlink" title="拥塞控制原理"></a>拥塞控制原理</h2><h3 id="拥塞原因"><a href="#拥塞原因" class="headerlink" title="拥塞原因"></a>拥塞原因</h3><ul><li>发送速度达到吞吐量上限</li><li>发生超时，重传分组过多导致。当持续升高发送速率，传输速率甚至可能不增加（重传分组也在增加），浪费了传输能力。</li><li>一个分组在一个路径上被舍弃掉时，在舍弃之前的传输容量被浪费了</li></ul><h3 id="拥塞控制方法"><a href="#拥塞控制方法" class="headerlink" title="拥塞控制方法"></a>拥塞控制方法</h3><ul><li><strong>端到端控制</strong>，端系统通过一些网络拥塞的迹象来决定拥塞控制</li><li><strong>网络辅助控制</strong>，路由器向发送方提供关于网络拥塞状态的显式信息。一般有两种反馈方式。第一种为直接反馈，直接向发送方发送<strong>阻塞分组</strong>。第二种为标记发送方到接收方的分组的某个字段来反馈。</li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>应用层</title>
    <link href="/2024/09/12/%E5%BA%94%E7%94%A8%E5%B1%82/"/>
    <url>/2024/09/12/%E5%BA%94%E7%94%A8%E5%B1%82/</url>
    
    <content type="html"><![CDATA[<h2 id="应用层协议原理"><a href="#应用层协议原理" class="headerlink" title="应用层协议原理"></a>应用层协议原理</h2><p>在具体的讨论所有概念之前，需要先大致知道各个部分的关系是怎么样的。</p><h3 id="网络应用程序体系结构"><a href="#网络应用程序体系结构" class="headerlink" title="网络应用程序体系结构"></a>网络应用程序体系结构</h3><p>应用程序研发者需要决定程序使用的体系结构，一般有以下两种：</p><h4 id="客户-服务器体系结构-client-server-architecture"><a href="#客户-服务器体系结构-client-server-architecture" class="headerlink" title="客户-服务器体系结构(client-server architecture)"></a>客户-服务器体系结构(client-server architecture)</h4><p>服务器接收来自用户的请求，发送所请求的对象。服务器具有固定的ip地址。</p><h4 id="P2P体系结构"><a href="#P2P体系结构" class="headerlink" title="P2P体系结构"></a>P2P体系结构</h4><p>成对间歇连接的主机彼此直接通信。P2P的体系结构具有自拓展性，随着对等方数量增加，分发时间只会趋于一定值，而非线形增长。原因是对等方不仅是消费者还是重新分发者。</p><p>BitTorrent是一种流行的P2P协议，具有一些高效机制，比如一方可以给传输速度最快的对等方优先权。</p><h3 id="进程通信"><a href="#进程通信" class="headerlink" title="进程通信"></a>进程通信</h3><p>不同端系统上的进程通过交换<strong>报文</strong>来相互通信</p><h4 id="客户和服务器进程"><a href="#客户和服务器进程" class="headerlink" title="客户和服务器进程"></a>客户和服务器进程</h4><p>在一对进程，一个标识为客户，一个标识为服务器</p><h4 id="进程与计算机网络的接口"><a href="#进程与计算机网络的接口" class="headerlink" title="进程与计算机网络的接口"></a>进程与计算机网络的接口</h4><p>进程通过<strong>套接字</strong>(socket)来向网络发送报文&#x2F;接收报文</p><h4 id="进程寻址"><a href="#进程寻址" class="headerlink" title="进程寻址"></a>进程寻址</h4><p>为了让报文可以送给指定主机的指定进程，需要<strong>IP地址</strong> + <strong>端口号</strong>(port number)</p><h3 id="运输服务"><a href="#运输服务" class="headerlink" title="运输服务"></a>运输服务</h3><p>可以从四个方面对应用程序服务要求分类：</p><ul><li>可靠数据传输</li><li>吞吐量</li><li>定时</li><li>安全性</li></ul><h3 id="internet提供的运输服务"><a href="#internet提供的运输服务" class="headerlink" title="internet提供的运输服务"></a>internet提供的运输服务</h3><h4 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h4><p>TCP为一种面向连接的服务，在交换报文之前，会有握手阶段，即客户与服务器交换信息，完成该阶段才会建立TCP连接。</p><p>TCP确保了数据都是无差错并按顺序的。其拥有拥塞控制机制，当网络阻塞时，会抑制发送进程。</p><h4 id="UDP"><a href="#UDP" class="headerlink" title="UDP"></a>UDP</h4><p>无连接，无拥塞机制，直接注入数据。</p><h2 id="web和http"><a href="#web和http" class="headerlink" title="web和http"></a>web和http</h2><h3 id="http"><a href="#http" class="headerlink" title="http"></a>http</h3><p>http定义了web客户向服务器请求网页的方式。http使用TCP协议。客户和服务器都是通过socket与TCP连接，TCP为http提供可靠的数据传输服务。当用户试图请求一个网页，发生的过程如下：</p><ul><li>客户通过TCP向客户端发送http请求</li><li>客户端从TCP接收请求并发送http响应</li></ul><p>注意http为<strong>无状态协议</strong>，http服务器不会保存用户的任何信息。</p><p>同时，http既可以使用<strong>非持续连接</strong>，也可以使用<strong>持续连接</strong>。非持续连接，简单理解，即每个TCP连接在服务器发送了一个对象后关闭。持续连接，服务器在发送响应后，保持TCP连接打开。</p><p>http的请求报文<strong>格式</strong>：</p><figure class="highlight oxygene"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs oxygene">request line | <span class="hljs-keyword">method</span> <span class="hljs-title function_">url</span> <span class="hljs-title function_">version</span><br><span class="hljs-title function_">header</span> <span class="hljs-title function_">line</span>  | <span class="hljs-title function_">header_field_name</span> <span class="hljs-title function_">value</span><br>               <span class="hljs-title function_">header_field_name</span> <span class="hljs-title function_">value</span><br>               ...<br><span class="hljs-title function_">entity</span> <span class="hljs-title function_">body</span>  | ...<br><br></code></pre></td></tr></table></figure><p>比如：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs makefile">GET /somedir/page.html HTTP/1.1<br><span class="hljs-section">HOST: www.someschool.edu</span><br><span class="hljs-section">Connection: close</span><br><span class="hljs-section">User-agent: Mozilla/5.0</span><br><span class="hljs-section">Accept-language: en</span><br>(data data ...)<br></code></pre></td></tr></table></figure><p>请求行（Request Line）中定义了 HTTP 请求的关键参数。其中 Method 字段表示请求的方式，常用的请求方式为GET，POST。URL 字段用来定位资源，Version 字段用来说明当前使用的协议版本。头部行（Header Lines）中定义了可选的参数，用来辅助 HTTP 请求。数据域（Entity Body） 用来传输数据。</p><p>http的响应报文格式：</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs less"><span class="hljs-selector-tag">status</span> <span class="hljs-selector-tag">line</span> | <span class="hljs-selector-tag">version</span> <span class="hljs-selector-tag">status_code</span> <span class="hljs-selector-tag">phrase</span><br><span class="hljs-selector-tag">header</span> <span class="hljs-selector-tag">line</span>  | <span class="hljs-selector-tag">header_field_name</span> <span class="hljs-selector-tag">value</span><br>               <span class="hljs-selector-tag">header_field_name</span> <span class="hljs-selector-tag">value</span><br>               ...<br><span class="hljs-selector-tag">entity</span> <span class="hljs-selector-tag">body</span>  | ...<br></code></pre></td></tr></table></figure><p>比如</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-string">HTTP/1.1</span> <span class="hljs-number">200</span> <span class="hljs-string">OK</span><br><span class="hljs-attr">Connection:</span> <span class="hljs-string">close</span><br><span class="hljs-attr">Date:</span> <span class="hljs-string">Wed,</span> <span class="hljs-number">12</span> <span class="hljs-string">Aug</span> <span class="hljs-number">2019 12:00:01 </span><span class="hljs-string">GMT</span><br><span class="hljs-attr">Server:</span> <span class="hljs-string">Apache/2.2.3</span><br><span class="hljs-attr">Last-Modified:</span> <span class="hljs-string">Wed,</span> <span class="hljs-number">12</span> <span class="hljs-string">Aug</span> <span class="hljs-number">2019 9:11:03 </span><span class="hljs-string">GMT</span><br><span class="hljs-attr">Content-Length:</span> <span class="hljs-number">6821</span><br><span class="hljs-attr">Content-Type:</span> <span class="hljs-string">text/html</span><br><span class="hljs-string">(data</span> <span class="hljs-string">data</span> <span class="hljs-string">...)</span><br></code></pre></td></tr></table></figure><p>字段说明：</p><p>状态行（Status Line）定义了响应报文的关键参数。其中 Version 用来说明当前使用的协议版本，Status Code 表示请求结果的状态码，phrase 为状态码的说明。</p><p>头部行（Header Lines）中定义了可选的参数，用来辅助 HTTP 响应。</p><p>数据域（Entity Body） 用来传输数据。</p><p>常见的状态码</p><ul><li>200 OK：请求成功。</li><li>301 Moved Permanently：资源位置永久移动，新的url在响应报文的location中。</li><li>400 Bad Request：错误的请求，通用的差错代码。</li><li>404 Not Found：请求的资源不存在服务器中。</li><li>505 HTTP Version Not Supported：HTTP 协议版本不支持。</li></ul><h3 id="cookie"><a href="#cookie" class="headerlink" title="cookie"></a>cookie</h3><p>前面的http服务器都是无状态的。如果想将内容与用户联系起来，可以让http使用cookie。为了支持cookie，需要修改4个地方：</p><ul><li>http响应报文加入cookie首部行</li><li>http请求报文加入cookie首部行</li><li>用户端系统保留一个文件</li><li>后端数据库保留信息</li></ul><h3 id="web缓存"><a href="#web缓存" class="headerlink" title="web缓存"></a>web缓存</h3><p>可以配置浏览器指向web缓存器，其实就是cache。web缓存器即是客户也是服务器。通过设置web缓存器可以减少用户的响应时间。但是会有新的问题，就是，当网站更新，其缓存并不会更新，导致客户请求的是旧的。</p><p><strong>条件GET</strong>方法，允许缓存器证实请求的对象是最新的。</p><h2 id="电子邮件"><a href="#电子邮件" class="headerlink" title="电子邮件"></a>电子邮件</h2><h3 id="SMTP"><a href="#SMTP" class="headerlink" title="SMTP"></a>SMTP</h3><p>也是用户层的协议，与http在同一层。http主要是一个<strong>拉协议</strong>，而smtp主要是一个<strong>推协议</strong>。在发邮件时会使用到smtp，而在试图访问邮件时（相当于你查看你的邮箱），需要<strong>POP3&#x2F;IMAP&#x2F;HTTP</strong>。</p><h2 id="DNS"><a href="#DNS" class="headerlink" title="DNS"></a>DNS</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>(Domain Name System)。dns提供了将<strong>主机名</strong>到<strong>IP地址</strong>的转换的服务。包含了由<strong>DNS服务器</strong>实现的分布式数据库，和应用层协议（运行在udp上，端口为53）。</p><p>我们重新来访问一个网站，过程中发生以下事件：</p><ul><li>主机上运行着dns应用的客户端</li><li>浏览器从url提取主机名，传给dns客户端</li><li>dns客户端向dns服务器发送请求</li><li>dns客户端收到包含对应ip地址的回答报文</li><li>浏览器收到，向该ip地址发起连接</li></ul><h3 id="dns具体工作机理"><a href="#dns具体工作机理" class="headerlink" title="dns具体工作机理"></a>dns具体工作机理</h3><p>对于应用程序，如果需要将主机名转换为ip地址，只需要调用函数，比如<code>gethostbyname</code>，而dns的具体实现被抽象。下面来研究其机理。</p><p>dns的结构层次大概为以下：</p><ul><li>T0：<strong>根dns服务器</strong>：根服务器提供TLD服务器的ip地址</li><li>T1：<strong>TLD服务器</strong>：对于每个顶级域（如com、org、edu）和国家的顶级域（cn、uk、jp），都有TLD服务器。其提供权威dns服务器的ip地址</li><li>T2：<strong>权威dns服务器</strong>：所有公共可访问主机必须提供dns记录，权威dns服务器则收藏了这些dns记录。</li><li>T3：<strong>本地dns服务器</strong>：起到代理的作用，当主机发出dns请求时，将该请求转发到前几层。</li></ul><p>同样的，dns也具有缓存，使得大部分的dns查询可以绕过根服务器。</p><p>dns服务器上存储了<strong>资源记录</strong>(Resource Record)，每个dns回答报文中有多条RR，RR可以按下面的方法表示：</p><p><code>(name, value, type, ttl)</code></p><ul><li>type为A，则name是主机名，value为对应ip</li><li>type为NS，则name为域，value是知道 如何获取 该域的主机名的ip 的权威dns的主机名（有点绕）</li><li>type为CNAME，则value是别名为name的主机对应的规范主机名</li><li>type为MX，则value为别名为name的邮件服务器的规范主机名</li></ul><h2 id="CDN"><a href="#CDN" class="headerlink" title="CDN"></a>CDN</h2><p>为了向全世界用户分发巨量数据，大部分视频流公司都会用<strong>内容分发网</strong>(Content Distribution Network)。CDN管理多个服务器，在服务器存储视频和其他内容，将用户请求定向到较好的CDN的位置。</p><h3 id="CDN操作"><a href="#CDN操作" class="headerlink" title="CDN操作"></a>CDN操作</h3><p>当我们向网站请求一个视频（每个视频都有一个url）时：</p><ul><li>用户点击视频链接，发送对于视频网站的dns请求</li><li>LDNS将该dns转到权威dns服务器，但该权威服务器不返回ip地址，而是返回一个cdn服务器的主机名</li><li>用户的LDNS发送第二个请求给cdn服务器，并得到指定的cdn服务器</li><li>用户得到该cdn节点的ip地址，建立连接，发送请求</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>Computer-Networking</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>并发</title>
    <link href="/2024/08/30/%E5%B9%B6%E5%8F%91/"/>
    <url>/2024/08/30/%E5%B9%B6%E5%8F%91/</url>
    
    <content type="html"><![CDATA[<h1 id="intro"><a href="#intro" class="headerlink" title="intro"></a>intro</h1><p>多线程共享相同的地址空间，但有不同的程序计数器和栈。</p><p>并发会引发十分多糟糕的问题，且人类的线性思维，适合观测串行运行的程序而非并行运行的程序，所以处理并发十分困难。详细的例子可以看jyy的os课体验一下<a href="https://www.bilibili.com/video/BV1jx4y1S7cP/?share_source=copy_web&vd_source=a9e41a90f038945729e9b5aa11e0cbc6">并发互斥</a></p><p><strong>临界区</strong>，(critical section)是指访问共享资源的代码。当多个线程同时进入临界区时，可能就会出现<strong>竞争条件</strong>(race condition)，导致计算机运行的结果具有<strong>不确定性</strong>(indeterminate)。为了避免出现竞态，线程应该使用互斥(mutual exclusion)原语。</p><p>我们希望拥有一些原子指令，他们可以构建出通用的集合，以此构建多线程代码。</p><h1 id="API"><a href="#API" class="headerlink" title="API"></a>API</h1><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// some basic api of thread</span><br><span class="hljs-comment">// to compile and exec multi-thread program:</span><br><span class="hljs-comment">// include pthread.h </span><br><span class="hljs-comment">// gcc ... -lpthread</span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;pthread.h&gt;</span></span><br><br><span class="hljs-comment">// to create a thread to start from function mythread</span><br><span class="hljs-comment">// and pass parameters args</span><br><span class="hljs-type">void</span> *<span class="hljs-title function_">mythread</span><span class="hljs-params">(<span class="hljs-type">void</span> *arg)</span>&#123;<br><span class="hljs-type">myret_t</span> *r;<br>...<br><span class="hljs-keyword">return</span> (<span class="hljs-type">void</span> *)r;<br>&#125;<br><span class="hljs-type">pthread_t</span> p;<br><span class="hljs-type">int</span> rc = pthread_create(&amp;p, <span class="hljs-literal">NULL</span>, mythread, &amp;args)<br><br><span class="hljs-comment">// to wait for thread to terminate</span><br><span class="hljs-type">myret_t</span> *m;<br>pthread_join(p, (<span class="hljs-type">void</span> **)&amp;m);<br><br><span class="hljs-comment">// to create a lock</span><br><span class="hljs-type">pthread_mutex_t</span> lock;<br><span class="hljs-type">int</span> r = pthread_mutex_init(&amp;lock, <span class="hljs-literal">NULL</span>);<br><br>pthread_mutex_lock(&amp;lock);<br>...<br>pthread_mutex_unlock(&amp;lock);<br><br><span class="hljs-comment">// other lock related function</span><br><span class="hljs-comment">// if lock is occupied, it failed</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">pthread_mutex_trylock</span><span class="hljs-params">(<span class="hljs-type">pthread_mutex_t</span> *mutex)</span>;<br><span class="hljs-comment">// if request timeout, it failed</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">pthread_mutex_timedlock</span><span class="hljs-params">(<span class="hljs-type">pthread_mutex_t</span> *mutex, <span class="hljs-keyword">struct</span> timespec *abs_timeout)</span>;<br><br><span class="hljs-comment">// use condition variable for multi-thread</span><br><span class="hljs-type">pthread_mutex_t</span> lock = PTHREAD_MUTEX_INITIALIZER;<br><span class="hljs-type">pthread_mutex_t</span> cond = PTHREAD_COND_INITIALIZER;<br><span class="hljs-comment">// thread1</span><br>pthread_mutex_lock(&amp;lock);<br><span class="hljs-keyword">while</span>(ready == <span class="hljs-number">0</span>)<br>pthread_cond_wait(&amp;cond, &amp;lock);<br>pthread_mutex_unlock(&amp;lock);<br><span class="hljs-comment">// thread2</span><br>pthread_mutex_lock(&amp;lock);<br>ready = <span class="hljs-number">1</span>;<br>pthread_cond_signal(&amp;cond);<br>pthread_mutex_unlock(&amp;lock);<br><br><br></code></pre></td></tr></table></figure><h1 id="Lock"><a href="#Lock" class="headerlink" title="Lock"></a>Lock</h1><p>最开始解决互斥的方案之一，是试图关闭中断。这种方法虽然简单但显然存在很多问题。比如出现恶意程序关闭中断并死循环，或者多处理器，等等。</p><p>显然用户不可以有暂停时间的权限，但操作系统可以有。我们可以编写一些原子指令来实现。</p><h2 id="原子指令"><a href="#原子指令" class="headerlink" title="原子指令"></a>原子指令</h2><p>一些基本的硬件支持的指令</p><ul><li><strong>test-and-set</strong>：检查标志是否为1，并设置为1</li><li><strong>compare-and-exchange</strong>：比较两个值并更新值</li><li><strong>load-link + store-condition</strong>：条件式存储判断在加载地址链接某个值后，该值有无变化，若无，才会成功。</li></ul><h2 id="自旋锁"><a href="#自旋锁" class="headerlink" title="自旋锁"></a>自旋锁</h2><p>自旋锁，通过一直自旋，利用CPU周期直到锁可用。显然，如果持有锁的线程发生上下文切换，其他线程就只能一直自旋，等待该进程，浪费过多的资源和时间。有以下的解决方法。</p><h3 id="放弃"><a href="#放弃" class="headerlink" title="放弃"></a>放弃</h3><p>当将要自旋时，线程可以主动放弃cpu，通过调用yield。但是，这样无法解决starving的问题，即可能导致进程处于让出的循环，直到其中一个线程终于释放锁。</p><h3 id="队列-休眠"><a href="#队列-休眠" class="headerlink" title="队列+休眠"></a>队列+休眠</h3><p>简单来说，我们可以通过队列来实现合理的调度，决定锁释放时谁抢到锁。核心思想是，在设置锁时，当多个线程同时竞争一把锁，未获得锁的线程会将自己加入队列并进入休眠。在释放锁时，会通过队列顺序来唤醒下一个线程。</p><p>值得注意的是，如果在进入休眠前，恰好锁释放了，可能导致该线程永久休眠，即wakeup&#x2F;waiting race。可以添加新的调用，即表明自己即将要休眠，若刚好在休眠前调用了唤醒，该线程在进入休眠后会立即返回。</p><h1 id="条件变量"><a href="#条件变量" class="headerlink" title="条件变量"></a>条件变量</h1><p>很多情况下，为了实现同步，线程常常检查某一条件满足之后才会继续运行。在之前的实现中，我们可以通过自旋锁来完成，但显然在浪费cpu的时间。所以我们希望<em>让未满足条件的进程休眠，直至条件满足时被唤醒</em>。</p><p>我们可以声明条件变量，并通过wait()还有signal()的操作，来使该线程休眠等待，或者唤醒另一个线程。</p><h2 id="生产者-消费者问题"><a href="#生产者-消费者问题" class="headerlink" title="生产者&#x2F;消费者问题"></a>生产者&#x2F;消费者问题</h2><p>描述一个模型：生产者负责将数据放入缓冲区，消费者负责将数据从缓冲区取走。两者都是线程。在执行的过程中，显然生产者的<em>条件</em>为缓冲区不满，消费者的<em>条件</em>为缓冲区不空，若不满足，可以通过上面的机制解决。真的吗？有什么要注意的问题？</p><h3 id="why-while"><a href="#why-while" class="headerlink" title="why while"></a>why while</h3><p>思考一下，如果我们用if来判断是否满足条件，判断出不满足时进入if让进程休眠，满足的话继续执行，最后唤醒其他进程。这在消费者和生产者都只有一个时，似乎可行，但如果消费者有两个呢？</p><p>若在一开始，缓冲区为空，两个消费者都进入了休眠状态。生产者填满了缓冲区，唤醒了消费者1，当消费者1就绪，正准备运行（从休眠处），消费者2抢先取数据（此时1还没有锁保护），轮到1时，1获取了锁，然后返回，但缓冲区已空。</p><p>上面的例子说明，当进程被唤醒时，只能<em>暗示有状态发生变化</em>，而不能推测在<em>执行前条件一直满足</em>。其次，用while代替if来判断是一个更好的选择。</p><p>还有问题吗？</p><h3 id="more-condition-variables"><a href="#more-condition-variables" class="headerlink" title="more condition variables"></a>more condition variables</h3><p>不止上面的问题呢，想象一下，还是上面的场景，但我们已经把if换成while了。当消费者1取数据，显然这时2因为不满足条件，休眠了。1取完后，发送信号唤醒一个进程。问题来了，好像可能会把2给叫醒，2醒来发现条件还是不满足，继续睡了。结果是三个线程全部进入了休眠。</p><p>解决该问题的方法也很简单，通过两个变量，来保证信号的指向性，消费者发送信号1，接受信号2，生产者发送信号2，接受信号1。</p><h3 id="covering-condition"><a href="#covering-condition" class="headerlink" title="covering condition"></a>covering condition</h3><p>覆盖条件。当不知道唤醒哪个线程可以满足条件时，考虑唤醒所有等待线程。即可以覆盖所有需要唤醒线程的场景。在单个变量的生产者&#x2F;消费者问题中，这是可行的。但如果程序只有改成广播信号，才能工作，大概率是程序本身有问题。（？</p><h1 id="信号量"><a href="#信号量" class="headerlink" title="信号量"></a>信号量</h1><p>信号量为一个整数。可以通过wait()和post()来操作它。可以初始化信号量的值。wait的功能为令信号量减1，如果信号量小于0，就休眠。post为令信号量加一，唤醒等待线程。先假设信号量的变化都是原子的。</p><h2 id="二值信号量"><a href="#二值信号量" class="headerlink" title="二值信号量"></a>二值信号量</h2><p>顾名思义，信号量开始时为1。第一个接触信号量的线程1，将其变为0并运行。在其结束前，其他试图进入临界区的线程，将信号量减为-1，等待。直到线程1释放锁信号量为0。如果结束前都没有其他线程访问临界区，信号量会恢复成1。这样就可以用于构成一般的锁。</p><h2 id="信号量作条件变量"><a href="#信号量作条件变量" class="headerlink" title="信号量作条件变量"></a>信号量作条件变量</h2><p>用于使线程暂停运行等待条件成立。信号量的初值设为0。假设一个线程1创建线程2并等待其结束。若创建后2并不开始运行，则1会将信号量减为-1并开始等待，直到2将信号量增加为0。如果2立即开始运行，2结束前信号量都为-1，1不会运行，结束后2就可以运行了。</p><h2 id="生产者-消费者问题-1"><a href="#生产者-消费者问题-1" class="headerlink" title="生产者&#x2F;消费者问题"></a>生产者&#x2F;消费者问题</h2><p>实现其实在之前就写了，无非将对应的方法用信号量代替。但注意，如果我们在条件变量的外面加上锁，可能会导致<strong>死锁</strong>。比如，消费者持有锁，但在等消费的条件，当生产者试图运行时，因为没有锁，又进入等待。解决的方法就是缩小锁的范围，在条件变量内上锁。</p><h2 id="读者-写者锁"><a href="#读者-写者锁" class="headerlink" title="读者-写者锁"></a>读者-写者锁</h2><p>mian idea是，写者和读者间显然只能有一把锁，但一旦有一个读者拿到锁，其他读者也可以使用。（因为读并不会修改状态）。写者需要等待所有的读者结束后才能开始，所以可能会导致starving。</p><h2 id="哲学家就餐问题"><a href="#哲学家就餐问题" class="headerlink" title="哲学家就餐问题"></a>哲学家就餐问题</h2><p>假设有5个哲学家围在圆桌，两个哲学家之间放着一个餐具，每个哲学家需要左右手都拿到餐具才能开始吃饭。我们给餐具上锁，所以拿餐具的过程是原子的。若所有哲学家的策略都是一样的，先拿左手边的餐具，若恰好他们都拿到了左手边的餐具，都在等右手的，这时就会都阻塞。</p><p>一种可行的解决方法是，让其中一人先取右边，来破除这种依赖。</p><h1 id="常见并发问题"><a href="#常见并发问题" class="headerlink" title="常见并发问题"></a>常见并发问题</h1><h2 id="非死锁缺陷"><a href="#非死锁缺陷" class="headerlink" title="非死锁缺陷"></a>非死锁缺陷</h2><p>该问题占了并发问题的大部分，主要讨论以下的内容</p><h3 id="违反原子性"><a href="#违反原子性" class="headerlink" title="违反原子性"></a>违反原子性</h3><p>指的是代码的愿意是原子的，然而并未按照原子性的实现。比如不加原子保护，判断一个指针非空后，试图访问改地址，有可能在访问时该指针已被其他线程变为空了。修复方法之一，就是加锁。</p><h3 id="违反顺序"><a href="#违反顺序" class="headerlink" title="违反顺序"></a>违反顺序</h3><p>指的是预期访问内存的顺序被打破（多线程的不确定性），导致的缺陷。显然，通过强制顺序来修复该缺陷，比如用条件变量来同步。</p><h2 id="死锁缺陷"><a href="#死锁缺陷" class="headerlink" title="死锁缺陷"></a>死锁缺陷</h2><h3 id="产生条件"><a href="#产生条件" class="headerlink" title="产生条件"></a>产生条件</h3><p>以下四个条件，只要一个不满足，死锁就不会产生：</p><ul><li><strong>互斥</strong>：比如需要抢锁</li><li><strong>持有并等待</strong>：线程持有资源（如：锁），又在等待其他资源（如：需要的另一把锁）</li><li><strong>非抢占</strong>：线程获得的资源，不能被抢占</li><li><strong>循环等待</strong>：线程形成环路，环路上每个线程都额外持有一个资源，而这个资源又是下一个线程需要的</li></ul><p>所以我们可以考虑四种策略，每种策略都试图阻止一个条件，从而避免死锁</p><h4 id="预防循环等待"><a href="#预防循环等待" class="headerlink" title="预防循环等待"></a>预防循环等待</h4><p>一个想法是，规定锁的获取必须有顺序。一种顺序叫全序(total ordering)，即全部锁都会按照一定的先后顺序获取，必须先申请锁1，才能申请锁2。然而在复杂的系统中，这可能很难做到，所以可以采用偏序(partial ordering)，仅包含所有锁中的几个锁的关系。</p><h4 id="预防持有等待"><a href="#预防持有等待" class="headerlink" title="预防持有等待"></a>预防持有等待</h4><p>可以原子抢锁来避免，原子地抢多个锁。然而这需要知道所需的全部锁，不适合封装，降低了并发。</p><h4 id="预防非抢占"><a href="#预防非抢占" class="headerlink" title="预防非抢占"></a>预防非抢占</h4><p>我们可以让线程在抢到锁1，抢不到锁2时，主动放出锁1。</p><p>值得注意的是，如果另一个线程的抢锁顺序不同，比如先2后1，可能会导致<strong>活锁</strong>，他们同时抢锁失败，一直循环。</p><p>这种方法的封装性一般，若代码在途中获得其他资源（比如内存），必须也要确保他们被释放。</p><h4 id="预防互斥"><a href="#预防互斥" class="headerlink" title="预防互斥"></a>预防互斥</h4><p>不用锁，而使用硬件支持的原子操作。</p><h3 id="调度"><a href="#调度" class="headerlink" title="调度"></a>调度</h3><p>除了死锁的预防，我们还可以通过调度来避免死锁。让不竞争资源的线程并行运行，竞争的串行。</p><h3 id="检查-恢复"><a href="#检查-恢复" class="headerlink" title="检查&#x2F;恢复"></a>检查&#x2F;恢复</h3><p>允许死锁发生，采用死锁的检测和恢复技术。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Operating System</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>内存虚拟化</title>
    <link href="/2024/08/30/%E5%86%85%E5%AD%98%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    <url>/2024/08/30/%E5%86%85%E5%AD%98%E8%99%9A%E6%8B%9F%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h1 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h1><p>虚拟内存具有以下目标：</p><ul><li>透明：即程序会被欺骗得很好</li><li>效率：在虚拟化时，为了提高效率，需要硬件支持</li><li>保护：确保各个进程的隔离</li></ul><h1 id="地址转换"><a href="#地址转换" class="headerlink" title="地址转换"></a>地址转换</h1><p>先从简单的机制入手（后面会更复杂）</p><h2 id="动态重定位"><a href="#动态重定位" class="headerlink" title="动态重定位"></a>动态重定位</h2><p>基于硬件，最简单的重定位。每个cpu需要加入两个硬件寄存器：<strong>base</strong>和<strong>bound</strong>。当程序执行时，操作系统会决定其基址，设置base寄存器，然后该进程的所有进程引用都会被处理为物理地址：</p><p><code>paddr = vaddr + base</code></p><p>bound寄存器则提供了保护机制，当进程试图越界，会触发异常处理。</p><p>十分明显，这种方法效率低下，进程可能浪费大量内存。</p><h2 id="分段机制"><a href="#分段机制" class="headerlink" title="分段机制"></a>分段机制</h2><p>为了解决上面的问题，我们引入分段的机制。每个段都记录基址，以及界限。则处理地址的过程可以变为：</p><p><code>paddr = bias + base</code></p><p>偏移量可以通过虚拟地址计算出来。可以用虚拟地址的前几位来表示目标段：</p><p><code>[ s1 | s0 | v11 | ... | v0 ]</code></p><p>注意到栈的机制，我们不可以直接用虚拟地址来当偏移量，可以再增加一位用来记录是否反向增长。</p><p>该机制还可以提高保护，比如再引进一位用来记录段的权限。</p><p>物理内存的一个段可以映射到多个虚拟地址空间。</p><p>但该方法无法避免内存碎片，只能减少。需要更好的机制。</p><h1 id="空闲空间管理"><a href="#空闲空间管理" class="headerlink" title="空闲空间管理"></a>空闲空间管理</h1><p>先考虑外部碎片，即由于空闲空间大小不一，导致总空闲空间足够，但因为不连续而导致无法分配。</p><p>主要讲了一些合并与寻找空闲块的策略。</p><h2 id="基本策略"><a href="#基本策略" class="headerlink" title="基本策略"></a>基本策略</h2><ul><li>最优匹配：找候选块最小的可满足的，减少碎片大小</li><li>最差匹配：找候选最大的，留大块碎片（通常糟糕）</li><li>首次匹配：找第一个符合的，速度快</li><li>下次匹配：从上次分配的位置接着往后找</li></ul><h2 id="分离空闲列表"><a href="#分离空闲列表" class="headerlink" title="分离空闲列表"></a>分离空闲列表</h2><p>（不是很理解）</p><h2 id="伙伴系统"><a href="#伙伴系统" class="headerlink" title="伙伴系统"></a>伙伴系统</h2><p>将空闲空间一直二分，直到满足。这样释放的时候，检查伙伴的块，可以实现递归合并。且由于这种机制，一对伙伴之间的地址关系很显然：他们只有一位不同。</p><h1 id="分页"><a href="#分页" class="headerlink" title="分页"></a>分页</h1><p>前面分段的方法，将空间切分成长度不同的部分，造成碎片。我们可以试试将物理内存定长分割，每一块叫做<strong>页</strong>。这种方法抽象程度更高，通过虚拟页与物理页映射，不用考虑进程怎么使用地址。</p><p>通过<strong>页表</strong>，实现虚拟页号（VPN）到物理页号（PFN）的转换。页表记录vpn与pfn的映射关系。比如：<br><code>[vpn|offset] -&gt; [pfn|offset]</code>实际上就完成了地址的转换。</p><h2 id="页表"><a href="#页表" class="headerlink" title="页表"></a>页表</h2><p>在哪？我们可以建立一个<strong>页表基址寄存器</strong>(PTBR)来记录。现在我们可以用伪代码来模拟这个过程：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// extract vpn</span><br>vpn = (vaddr &amp; vpn_mask) &gt;&gt; shift<br><br><span class="hljs-comment">// get pte</span><br>pte_addr = ptbr + vpn * <span class="hljs-keyword">sizeof</span>(pte)<br>pte = M(pte_addr)<br><br><span class="hljs-comment">// check if can process page</span><br><span class="hljs-keyword">if</span>(pte.valid == <span class="hljs-literal">false</span>)<br>error(segmentation fault)<br><span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(pte.ifprotect == <span class="hljs-literal">true</span>)<br>error(protection fault)<br><span class="hljs-keyword">else</span><br>offset = vpn &amp; offset_mask<br>paddr = (pte.pfn &lt;&lt; shift) | offset<br>r = M(paddr)<br></code></pre></td></tr></table></figure><h2 id="TLB"><a href="#TLB" class="headerlink" title="TLB"></a>TLB</h2><p>由学过的储存器层次结构，caching是一种能加速内存访问的技术，应用于页表，就是TLB。TLB将前面的PTE表项拿来作为表项。</p><p>处理未命中时，系统抛出异常，加载更新TLB，再回到指令处重新执行。注意并非下一条指令，与之前讲的中断不一样。同时要注意无限递归，即异常处理程序本身不在TLB中。TLB为全相联的结构，所以可以直接并行查找，速度快。</p><p>因为不同的进程映射关系不同，理论上上下文切换时，应该清空TLB，但这样开销太大，可以考虑为TLB加上地址空间标识符（ASID）</p><p>一些替换策略：</p><ul><li>LRU</li><li>随机：避免上面方法的抖动现象</li></ul><h2 id="更小的页表"><a href="#更小的页表" class="headerlink" title="更小的页表"></a>更小的页表</h2><p>从上面知道，页表的项数为：2的 分配给页表的位数 次方，显然，页表本身为一笔不小的开销。我们思考以下方法：</p><p><strong>更大的页</strong>：通过减少vpn的位数从而减少页表，但内部碎片过大</p><p><strong>分段分页混合</strong>：我们不为整个进程提供页表，只对三个逻辑分段提供。之前每段都有一对基址界限寄存器，现在让基址寄存器记录该段的页表上的位置，界限记录有多少有效页。</p><p><strong>多级页表</strong>：本质就是将之前的页表分成页，用高一级的页表记录。好处是，当有一个<strong>页</strong>的页表项没有记录东西，我们可以在高一级的页表上用有效为0的表项来表示，从而避免给空页表分配空间。如下：</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs coq">[   vpn     |   <span class="hljs-type">offset</span>  ]<br>[ pti | <span class="hljs-type">pfn</span> |   <span class="hljs-type">offset</span>  ]<br>[pd1|<span class="hljs-type">pd0</span>|<span class="hljs-type">pfn</span>|   <span class="hljs-type">offset</span>  ]<br>...<br></code></pre></td></tr></table></figure><h2 id="超越物理内存"><a href="#超越物理内存" class="headerlink" title="超越物理内存"></a>超越物理内存</h2><h3 id="机制"><a href="#机制" class="headerlink" title="机制"></a>机制</h3><p>我们之前都是假设虚拟内存的空间地址小于物理内存的，为了支持运行更多更大的进程需要在内存层级（memory hierarchy）上加层。</p><p>在这里，我们考虑在物理内存下加上硬盘，并在硬盘上开辟交换空间。</p><p>为了支持交换空间，我们需要添加更多机制。比如在页表项添加存在位，表示该页是否在物理内存中。如果不在，会触发<strong>页错误</strong>。触发之后，会通过硬盘的I&#x2F;O来更新页表。注意在I&#x2F;O运行时，进程阻塞，此时可以执行其他进程，就是cpu虚拟化里提到的[[CPU虚拟化#overlap]]</p><p>同时，操作系统并非等到内存满才会交换页，实际上它可以主动预留一小部分内存。设置<strong>高水位线</strong>（HW）和<strong>低水位线</strong>（LW），当操作系统发现少于LW个页可用，会执行后台释放内存的进程直到有HW个页可用。</p><p>还有，通过同时执行多个交换过程，可以提高性能。</p><h3 id="策略"><a href="#策略" class="headerlink" title="策略"></a>策略</h3><p>为了效率，应该思考在页替换时的选择策略。</p><p><strong>最优替换策略</strong>：本质上需要可以预知未来。是一种无法实现，但可以作为参照（用于评估另一种算法好坏）的方法。具体是替换最远将来会访问的页（听着就很科幻）。</p><p><strong>FIFO</strong>：最先进入缓存的页out，缺点是其无法确定页的重要性。</p><p><strong>随机</strong>：看运气，也是不够智能</p><p><strong>LRU</strong>：可以通过历史记录，在执行替换时，踢出最少最近使用的页。</p><p><strong>近似LRU</strong>：LRU因为需要扫描所有页来实现替换，开销太大。以下是一种近似方法。给硬件增加使用位（use bit），每当页被引用时，使用位设置为1。我们采取<strong>时钟算法</strong>，当需要替换时，时钟指针检查当前指向的页的使用位，如果为1，则将其设置为0，并指向下一页，直到遇到使用位为0的页。</p><p>脏页。因为在内存中，一个没有修改过的页显然写回成本要小于修改过的（因为可以直接释放，不用进行I&#x2F;O）。所以可以考虑加一个脏位（dirty bit）。</p><p>还有一些策略：比如<strong>预取</strong>，<strong>聚集写入</strong>等。</p><h2 id="VAX-VMS"><a href="#VAX-VMS" class="headerlink" title="VAX&#x2F;VMS"></a>VAX&#x2F;VMS</h2><p>主要研究该操作系统的一些有意思的虚拟内存管理。</p><h3 id="地址空间"><a href="#地址空间" class="headerlink" title="地址空间"></a>地址空间</h3><p>内核虚拟空间是每个用户地址空间的一部分。在上下文切换时，该段的基址界限寄存器不会变，本质是将相同的地址空间映射到各个用户。</p><h3 id="页替换策略"><a href="#页替换策略" class="headerlink" title="页替换策略"></a>页替换策略</h3><p><strong>分段的FIFO的策略</strong>：每个进程都有一个可以保留在内存中的最大页数（resident set size），当超过RSS时，先入被驱逐。VMS还引入了二次机会列表（second- chance list），分别为一个全局干净列表和脏列表。页在被踢出之前放在这里。</p><p><strong>页聚集</strong>：将大批量的脏页分组到一起，并一举写入磁盘。</p><h3 id="惰性优化"><a href="#惰性优化" class="headerlink" title="惰性优化"></a>惰性优化</h3><p><strong>按需置零</strong>：当用户添加页到堆，（比如malloc），并不直接分配一个置零的页，而是只在页表里放入一个不可访问的条目。当用户需要读取或者写入该页，才会寻找物理页，将其置0并映射到地址空间。而如果进程不访问这页，就直接省去了这个开销。</p><p><strong>写时复制</strong>：若操作系统需要将一个页面从一个地址空间复制到另一个（比如fork），不会实际复制，而是将其映射到目标地址空间并标记为只读。当需要写的时候，才会分配新页填充数据并重新映射。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Operating System</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CPU虚拟化</title>
    <link href="/2024/08/30/CPU%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    <url>/2024/08/30/CPU%E8%99%9A%E6%8B%9F%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h1 id="intro"><a href="#intro" class="headerlink" title="intro"></a>intro</h1><blockquote><p>线程简单理解：一个<strong>进程</strong>里可以有多个线程，线程可以看作小的进程。同一个进程下的线程共享全局变量和堆内存。</p></blockquote><h1 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h1><h2 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h2><p>现代操作系统lazily执行该过程，只有到需要时才会加载数据到进程的地址空间。</p><h3 id="API"><a href="#API" class="headerlink" title="API"></a>API</h3><h4 id="fork"><a href="#fork" class="headerlink" title="fork"></a>fork</h4><p>拷贝父进程，但从fork开始执行。同时fork的返回值，子进程是0，父进程为子进程的pid。</p><h4 id="wait"><a href="#wait" class="headerlink" title="wait"></a>wait</h4><p>延迟进程的执行，直到子进程运行完毕才返回</p><h4 id="exec"><a href="#exec" class="headerlink" title="exec"></a>exec</h4><p>并无创建子进程，而是将当前运行的程序替换为不同的运行程序。通过参数来重新初始化代码段、堆、栈等。</p><p>fork和exec的分开可以实现很多功能。shell：先找到可执行程序，接着fork新进程，在新进程里面exec程序，最后wait直到进程结束。比如shell的重定向。</p><p>如：<code>$ cat hello.c &gt; hello.txt</code>，在运行cat之前，先打开hello.txt，关闭stdout，然后再运行，就可以实现重定向。</p><h1 id="limited-direct-execution"><a href="#limited-direct-execution" class="headerlink" title="limited direct execution"></a>limited direct execution</h1><h2 id="限制操作"><a href="#限制操作" class="headerlink" title="限制操作"></a>限制操作</h2><p>为了让进程可以安全地在cpu上运行，引入不同的模式：</p><ul><li>user mode：行为受限</li><li>kernel mode：可以实现特权操作。<br>执行系统调用时，会通过<strong>trap</strong>来跳入内核并切换模式。通过内核启动时设置的<strong>trap table</strong>来跳转到相应的异常处理代码</li></ul><h2 id="进程切换"><a href="#进程切换" class="headerlink" title="进程切换"></a>进程切换</h2><h3 id="cooperative"><a href="#cooperative" class="headerlink" title="cooperative"></a>cooperative</h3><p>当应用程序结束、异常、运行时间过长，或者通过系统调用，控制权回归操作系统。（理想的程序）</p><h3 id="timer-interrupt"><a href="#timer-interrupt" class="headerlink" title="timer interrupt"></a>timer interrupt</h3><p>时钟为设备产生周期性的中断，控制权还给操作系统，让os决定接下来运行什么。</p><h3 id="context"><a href="#context" class="headerlink" title="context"></a>context</h3><p>保存恢复上下文，即上下文切换。为当前的进程保存状态（寄存器etc），为接下来的进程恢复状态。注意与上文的中断不同，前者隐式保存用户的寄存器到该进程的内核栈，后者显示保存到该进程结构的内存（通过保存指针，来保存和恢复状态）（？）</p><h1 id="进程调度基础"><a href="#进程调度基础" class="headerlink" title="进程调度基础"></a>进程调度基础</h1><h2 id="指标"><a href="#指标" class="headerlink" title="指标"></a>指标</h2><p>对于每个进程：<br>周转时间 &#x3D; 完成时间 - 到达时间 （性能）<br>响应时间 &#x3D; 首次运行时间 - 到达时间（公平）</p><h2 id="SJF"><a href="#SJF" class="headerlink" title="SJF"></a>SJF</h2><p><strong>shortest job first</strong>，先运行最短时间的任务。对比FIFO的工作方式，周转时间降低。</p><h2 id="STCF"><a href="#STCF" class="headerlink" title="STCF"></a>STCF</h2><p><strong>shortest time-to-complete first</strong>，又称抢占式任务优先，每当有新工作加入系统，都会确定哪个工作的剩余时间最小，周转时间降低。</p><h2 id="RR"><a href="#RR" class="headerlink" title="RR"></a>RR</h2><p>轮转调度，将工作变成多个时间切片，循环执行不同工作的切片。时间片变短，响应时间越高，但相对的上下文切换的成本提高。公平和性能是一对需要权衡的因素，不可兼得。</p><h2 id="overlap"><a href="#overlap" class="headerlink" title="overlap"></a>overlap</h2><p>一个工作使用I&#x2F;O的时间，可以看成是独立于该工作。则另一个工作可以利用I&#x2F;O运行的时间。</p><h1 id="MLFQ"><a href="#MLFQ" class="headerlink" title="MLFQ"></a>MLFQ</h1><p><strong>multi-level feedback queue</strong>，多级反馈队列，其维护了多个优先级不同的队列，每个工作只存在于一个队列中，不同的队列有不同的时间配额，利用反馈的信息来决定工作的优先级。下面是其规则：</p><ul><li>A的优先级 &gt; B的优先级，则运行A而不运行B</li><li>A的优先级 &#x3D; B的优先级，则轮转运行A和B</li><li>工作进入系统时，放在最高优先级的队列</li><li>一旦工作用完了其在该队列的时间配额，就降低其优先级</li><li>经过一段时间S，所有工作重新加入最优先队列</li></ul><h1 id="proportional-share"><a href="#proportional-share" class="headerlink" title="proportional-share"></a>proportional-share</h1><p>比例份额调度</p><h2 id="lottery-share"><a href="#lottery-share" class="headerlink" title="lottery share"></a>lottery share</h2><p>进程运行越久，其彩票越多。在每次调度决策之前，都会抽出一个数字（中奖号码），显然，彩票越多的进程，中奖概率越大，则作为下一个运行的对象。该方法运用了随机性，当运行时间足够长时，不同工作的时间比例会趋于期望。实现上，比较轻量。</p><p>和LRU替换算法进行对比，LRU在遇到重复循环序列时，性能低。而彩票调度可以避免。</p><h2 id="stride-scheduling"><a href="#stride-scheduling" class="headerlink" title="stride scheduling"></a>stride scheduling</h2><p>步长调度，算法始终选择行程值最小的工作。严格实现，在每次调度都是正确的比例。</p><p>然而以上两种方法都不常用。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Operating System</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Squeeze Compressor</title>
    <link href="/2024/08/30/Squeeze-Compressor/"/>
    <url>/2024/08/30/Squeeze-Compressor/</url>
    
    <content type="html"><![CDATA[<h2 id="overview"><a href="#overview" class="headerlink" title="overview"></a>overview</h2><p>核心的想法是：对于可精确预测的数据，通过曲线拟合；对于难以合适预测的数据，通过二进制表示的分析来进行有损压缩。</p><h2 id="implement"><a href="#implement" class="headerlink" title="implement"></a>implement</h2><p>压缩前需要的三个参数：绝对误差范围、相对误差范围、压缩率</p><p>以下是压缩的具体算法：</p><h3 id="convert-array"><a href="#convert-array" class="headerlink" title="convert array"></a>convert array</h3><p>通过实验发现，建立曲线是压缩中最大的时间开销。鉴于有<strong>较低的转换开销</strong>、<strong>良好地保留了局部性</strong>的两个优势，使用数据数组原来在内存中的序列用来压缩会更好。</p><h3 id="curve-fitting"><a href="#curve-fitting" class="headerlink" title="curve-fitting"></a>curve-fitting</h3><p>每个数据点都会检查其能否根据先前的数据，使用以下三种曲线近似方法的一种来表示，若可以，易知即可压缩成2bit的数据。</p><ul><li>PNF：通过前一个数据点的<strong>原数据</strong>来预测（01）</li><li>LCF：前两个数据点的<strong>原数据</strong>的线性估计（10）</li><li>QCF：通过前三个数据点的二次曲线来预测（11）</li><li>无法预测：（00）</li></ul><p>该部分会分为以下几步来实现：<br>假设有M个数据点</p><ul><li>分配2Mbits的内存，用于存放压缩后的数据</li><li>计算数据值的变化范围</li><li>检查数据点，决定近似方法，若可近似，将对应的编号写入内存处；若不可近似，则通过对二进制表示的分析来压缩，并写入另一个数组</li></ul><p>由以上的算法，可以看出，该部分的时间复杂度为O(n)，时间和数据量成线性关系十分优秀。</p><h3 id="binary-representation-analysis"><a href="#binary-representation-analysis" class="headerlink" title="binary representation analysis"></a>binary representation analysis</h3><p>以下是二进制表示分析的过程</p><ul><li>通过将所有数据减去中位数，产生<strong>规范化数据</strong>，以缩小数值的范围（可以用更少的位数来表示）</li><li>接着，在误差允许的范围内，抛弃部分影响不大的有效位，再计算需要多少位来表示（注意此处最小的单位为字节，需要将结果约成8的倍数）</li><li>最后，计算需要填充的0的数量，用2bits即可表示（单位为一个全0的字节）</li></ul><h2 id="further-explore"><a href="#further-explore" class="headerlink" title="further explore"></a>further explore</h2><p>SZ压缩提高了数据压缩的速度以及压缩率。可以应用于CPU、GPU、FPGA以及其他科研领域。上文只是SZ的最初实现（SZ 0.1-1.0)的算法。目前SZ以及更新到SZ 3.0了</p><h2 id="citations"><a href="#citations" class="headerlink" title="citations"></a>citations</h2><p>大部分内容来自于以下的论文：</p><ul><li>SZ 0.1-1.0: Sheng Di, Franck Cappello, “<a href="https://ieeexplore.ieee.org/document/7516069">Fast Error-bounded Lossy HPC Data Compression with SZ</a>“, in IEEE International Parallel and Distributed Processing Symposium (IPDPS 2016), Chicago, IL, USA, 2016.</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>research</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>test2</title>
    <link href="/2024/08/30/test2/"/>
    <url>/2024/08/30/test2/</url>
    
    <content type="html"><![CDATA[<h1 id="进行一些简单的测试"><a href="#进行一些简单的测试" class="headerlink" title="进行一些简单的测试"></a>进行一些简单的测试</h1><h2 id="标题测试"><a href="#标题测试" class="headerlink" title="标题测试"></a>标题测试</h2><h1 id="h1"><a href="#h1" class="headerlink" title="h1"></a>h1</h1><h2 id="h2"><a href="#h2" class="headerlink" title="h2"></a>h2</h2><h3 id="h3"><a href="#h3" class="headerlink" title="h3"></a>h3</h3><h4 id="h4"><a href="#h4" class="headerlink" title="h4"></a>h4</h4><h2 id="代码块测试"><a href="#代码块测试" class="headerlink" title="代码块测试"></a>代码块测试</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c">hello, world!<br></code></pre></td></tr></table></figure><h2 id="列表测试"><a href="#列表测试" class="headerlink" title="列表测试"></a>列表测试</h2><ul><li>1</li><li>2</li><li>3</li></ul><h2 id="数学公式"><a href="#数学公式" class="headerlink" title="数学公式"></a>数学公式</h2><p>$$<br>x &#x3D; 1<br>$$</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2024/08/29/hello-world/"/>
    <url>/2024/08/29/hello-world/</url>
    
    <content type="html"><![CDATA[<p>It starts here.</p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
