<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>并发</title>
    <link href="/2024/08/30/%E5%B9%B6%E5%8F%91/"/>
    <url>/2024/08/30/%E5%B9%B6%E5%8F%91/</url>
    
    <content type="html"><![CDATA[<h1 id="intro"><a href="#intro" class="headerlink" title="intro"></a>intro</h1><p>多线程共享相同的地址空间，但有不同的程序计数器和栈。</p><p>并发会引发十分多糟糕的问题，且人类的线性思维，适合观测串行运行的程序而非并行运行的程序，所以处理并发十分困难。详细的例子可以看jyy的os课体验一下<a href="https://www.bilibili.com/video/BV1jx4y1S7cP/?share_source=copy_web&vd_source=a9e41a90f038945729e9b5aa11e0cbc6">并发互斥</a></p><p><strong>临界区</strong>，(critical section)是指访问共享资源的代码。当多个线程同时进入临界区时，可能就会出现<strong>竞争条件</strong>(race condition)，导致计算机运行的结果具有<strong>不确定性</strong>(indeterminate)。为了避免出现竞态，线程应该使用互斥(mutual exclusion)原语。</p><p>我们希望拥有一些原子指令，他们可以构建出通用的集合，以此构建多线程代码。</p><h1 id="API"><a href="#API" class="headerlink" title="API"></a>API</h1><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// some basic api of thread</span><br><span class="hljs-comment">// to compile and exec multi-thread program:</span><br><span class="hljs-comment">// include pthread.h </span><br><span class="hljs-comment">// gcc ... -lpthread</span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;pthread.h&gt;</span></span><br><br><span class="hljs-comment">// to create a thread to start from function mythread</span><br><span class="hljs-comment">// and pass parameters args</span><br><span class="hljs-type">void</span> *<span class="hljs-title function_">mythread</span><span class="hljs-params">(<span class="hljs-type">void</span> *arg)</span>&#123;<br><span class="hljs-type">myret_t</span> *r;<br>...<br><span class="hljs-keyword">return</span> (<span class="hljs-type">void</span> *)r;<br>&#125;<br><span class="hljs-type">pthread_t</span> p;<br><span class="hljs-type">int</span> rc = pthread_create(&amp;p, <span class="hljs-literal">NULL</span>, mythread, &amp;args)<br><br><span class="hljs-comment">// to wait for thread to terminate</span><br><span class="hljs-type">myret_t</span> *m;<br>pthread_join(p, (<span class="hljs-type">void</span> **)&amp;m);<br><br><span class="hljs-comment">// to create a lock</span><br><span class="hljs-type">pthread_mutex_t</span> lock;<br><span class="hljs-type">int</span> r = pthread_mutex_init(&amp;lock, <span class="hljs-literal">NULL</span>);<br><br>pthread_mutex_lock(&amp;lock);<br>...<br>pthread_mutex_unlock(&amp;lock);<br><br><span class="hljs-comment">// other lock related function</span><br><span class="hljs-comment">// if lock is occupied, it failed</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">pthread_mutex_trylock</span><span class="hljs-params">(<span class="hljs-type">pthread_mutex_t</span> *mutex)</span>;<br><span class="hljs-comment">// if request timeout, it failed</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">pthread_mutex_timedlock</span><span class="hljs-params">(<span class="hljs-type">pthread_mutex_t</span> *mutex, <span class="hljs-keyword">struct</span> timespec *abs_timeout)</span>;<br><br><span class="hljs-comment">// use condition variable for multi-thread</span><br><span class="hljs-type">pthread_mutex_t</span> lock = PTHREAD_MUTEX_INITIALIZER;<br><span class="hljs-type">pthread_mutex_t</span> cond = PTHREAD_COND_INITIALIZER;<br><span class="hljs-comment">// thread1</span><br>pthread_mutex_lock(&amp;lock);<br><span class="hljs-keyword">while</span>(ready == <span class="hljs-number">0</span>)<br>pthread_cond_wait(&amp;cond, &amp;lock);<br>pthread_mutex_unlock(&amp;lock);<br><span class="hljs-comment">// thread2</span><br>pthread_mutex_lock(&amp;lock);<br>ready = <span class="hljs-number">1</span>;<br>pthread_cond_signal(&amp;cond);<br>pthread_mutex_unlock(&amp;lock);<br><br><br></code></pre></td></tr></table></figure><h1 id="Lock"><a href="#Lock" class="headerlink" title="Lock"></a>Lock</h1><p>最开始解决互斥的方案之一，是试图关闭中断。这种方法虽然简单但显然存在很多问题。比如出现恶意程序关闭中断并死循环，或者多处理器，等等。</p><p>显然用户不可以有暂停时间的权限，但操作系统可以有。我们可以编写一些原子指令来实现。</p><h2 id="原子指令"><a href="#原子指令" class="headerlink" title="原子指令"></a>原子指令</h2><p>一些基本的硬件支持的指令</p><ul><li><strong>test-and-set</strong>：检查标志是否为1，并设置为1</li><li><strong>compare-and-exchange</strong>：比较两个值并更新值</li><li><strong>load-link + store-condition</strong>：条件式存储判断在加载地址链接某个值后，该值有无变化，若无，才会成功。</li></ul><h2 id="自旋锁"><a href="#自旋锁" class="headerlink" title="自旋锁"></a>自旋锁</h2><p>自旋锁，通过一直自旋，利用CPU周期直到锁可用。显然，如果持有锁的线程发生上下文切换，其他线程就只能一直自旋，等待该进程，浪费过多的资源和时间。有以下的解决方法。</p><h3 id="放弃"><a href="#放弃" class="headerlink" title="放弃"></a>放弃</h3><p>当将要自旋时，线程可以主动放弃cpu，通过调用yield。但是，这样无法解决starving的问题，即可能导致进程处于让出的循环，直到其中一个线程终于释放锁。</p><h3 id="队列-休眠"><a href="#队列-休眠" class="headerlink" title="队列+休眠"></a>队列+休眠</h3><p>简单来说，我们可以通过队列来实现合理的调度，决定锁释放时谁抢到锁。核心思想是，在设置锁时，当多个线程同时竞争一把锁，未获得锁的线程会将自己加入队列并进入休眠。在释放锁时，会通过队列顺序来唤醒下一个线程。</p><p>值得注意的是，如果在进入休眠前，恰好锁释放了，可能导致该线程永久休眠，即wakeup&#x2F;waiting race。可以添加新的调用，即表明自己即将要休眠，若刚好在休眠前调用了唤醒，该线程在进入休眠后会立即返回。</p><h1 id="条件变量"><a href="#条件变量" class="headerlink" title="条件变量"></a>条件变量</h1><p>很多情况下，为了实现同步，线程常常检查某一条件满足之后才会继续运行。在之前的实现中，我们可以通过自旋锁来完成，但显然在浪费cpu的时间。所以我们希望<em>让未满足条件的进程休眠，直至条件满足时被唤醒</em>。</p><p>我们可以声明条件变量，并通过wait()还有signal()的操作，来使该线程休眠等待，或者唤醒另一个线程。</p><h2 id="生产者-消费者问题"><a href="#生产者-消费者问题" class="headerlink" title="生产者&#x2F;消费者问题"></a>生产者&#x2F;消费者问题</h2><p>描述一个模型：生产者负责将数据放入缓冲区，消费者负责将数据从缓冲区取走。两者都是线程。在执行的过程中，显然生产者的<em>条件</em>为缓冲区不满，消费者的<em>条件</em>为缓冲区不空，若不满足，可以通过上面的机制解决。真的吗？有什么要注意的问题？</p><h3 id="why-while"><a href="#why-while" class="headerlink" title="why while"></a>why while</h3><p>思考一下，如果我们用if来判断是否满足条件，判断出不满足时进入if让进程休眠，满足的话继续执行，最后唤醒其他进程。这在消费者和生产者都只有一个时，似乎可行，但如果消费者有两个呢？</p><p>若在一开始，缓冲区为空，两个消费者都进入了休眠状态。生产者填满了缓冲区，唤醒了消费者1，当消费者1就绪，正准备运行（从休眠处），消费者2抢先取数据（此时1还没有锁保护），轮到1时，1获取了锁，然后返回，但缓冲区已空。</p><p>上面的例子说明，当进程被唤醒时，只能<em>暗示有状态发生变化</em>，而不能推测在<em>执行前条件一直满足</em>。其次，用while代替if来判断是一个更好的选择。</p><p>还有问题吗？</p><h3 id="more-condition-variables"><a href="#more-condition-variables" class="headerlink" title="more condition variables"></a>more condition variables</h3><p>不止上面的问题呢，想象一下，还是上面的场景，但我们已经把if换成while了。当消费者1取数据，显然这时2因为不满足条件，休眠了。1取完后，发送信号唤醒一个进程。问题来了，好像可能会把2给叫醒，2醒来发现条件还是不满足，继续睡了。结果是三个线程全部进入了休眠。</p><p>解决该问题的方法也很简单，通过两个变量，来保证信号的指向性，消费者发送信号1，接受信号2，生产者发送信号2，接受信号1。</p><h3 id="covering-condition"><a href="#covering-condition" class="headerlink" title="covering condition"></a>covering condition</h3><p>覆盖条件。当不知道唤醒哪个线程可以满足条件时，考虑唤醒所有等待线程。即可以覆盖所有需要唤醒线程的场景。在单个变量的生产者&#x2F;消费者问题中，这是可行的。但如果程序只有改成广播信号，才能工作，大概率是程序本身有问题。（？</p><h1 id="信号量"><a href="#信号量" class="headerlink" title="信号量"></a>信号量</h1><p>信号量为一个整数。可以通过wait()和post()来操作它。可以初始化信号量的值。wait的功能为令信号量减1，如果信号量小于0，就休眠。post为令信号量加一，唤醒等待线程。先假设信号量的变化都是原子的。</p><h2 id="二值信号量"><a href="#二值信号量" class="headerlink" title="二值信号量"></a>二值信号量</h2><p>顾名思义，信号量开始时为1。第一个接触信号量的线程1，将其变为0并运行。在其结束前，其他试图进入临界区的线程，将信号量减为-1，等待。直到线程1释放锁信号量为0。如果结束前都没有其他线程访问临界区，信号量会恢复成1。这样就可以用于构成一般的锁。</p><h2 id="信号量作条件变量"><a href="#信号量作条件变量" class="headerlink" title="信号量作条件变量"></a>信号量作条件变量</h2><p>用于使线程暂停运行等待条件成立。信号量的初值设为0。假设一个线程1创建线程2并等待其结束。若创建后2并不开始运行，则1会将信号量减为-1并开始等待，直到2将信号量增加为0。如果2立即开始运行，2结束前信号量都为-1，1不会运行，结束后2就可以运行了。</p><h2 id="生产者-消费者问题-1"><a href="#生产者-消费者问题-1" class="headerlink" title="生产者&#x2F;消费者问题"></a>生产者&#x2F;消费者问题</h2><p>实现其实在之前就写了，无非将对应的方法用信号量代替。但注意，如果我们在条件变量的外面加上锁，可能会导致<strong>死锁</strong>。比如，消费者持有锁，但在等消费的条件，当生产者试图运行时，因为没有锁，又进入等待。解决的方法就是缩小锁的范围，在条件变量内上锁。</p><h2 id="读者-写者锁"><a href="#读者-写者锁" class="headerlink" title="读者-写者锁"></a>读者-写者锁</h2><p>mian idea是，写者和读者间显然只能有一把锁，但一旦有一个读者拿到锁，其他读者也可以使用。（因为读并不会修改状态）。写者需要等待所有的读者结束后才能开始，所以可能会导致starving。</p><h2 id="哲学家就餐问题"><a href="#哲学家就餐问题" class="headerlink" title="哲学家就餐问题"></a>哲学家就餐问题</h2><p>假设有5个哲学家围在圆桌，两个哲学家之间放着一个餐具，每个哲学家需要左右手都拿到餐具才能开始吃饭。我们给餐具上锁，所以拿餐具的过程是原子的。若所有哲学家的策略都是一样的，先拿左手边的餐具，若恰好他们都拿到了左手边的餐具，都在等右手的，这时就会都阻塞。</p><p>一种可行的解决方法是，让其中一人先取右边，来破除这种依赖。</p><h1 id="常见并发问题"><a href="#常见并发问题" class="headerlink" title="常见并发问题"></a>常见并发问题</h1><h2 id="非死锁缺陷"><a href="#非死锁缺陷" class="headerlink" title="非死锁缺陷"></a>非死锁缺陷</h2><p>该问题占了并发问题的大部分，主要讨论以下的内容</p><h3 id="违反原子性"><a href="#违反原子性" class="headerlink" title="违反原子性"></a>违反原子性</h3><p>指的是代码的愿意是原子的，然而并未按照原子性的实现。比如不加原子保护，判断一个指针非空后，试图访问改地址，有可能在访问时该指针已被其他线程变为空了。修复方法之一，就是加锁。</p><h3 id="违反顺序"><a href="#违反顺序" class="headerlink" title="违反顺序"></a>违反顺序</h3><p>指的是预期访问内存的顺序被打破（多线程的不确定性），导致的缺陷。显然，通过强制顺序来修复该缺陷，比如用条件变量来同步。</p><h2 id="死锁缺陷"><a href="#死锁缺陷" class="headerlink" title="死锁缺陷"></a>死锁缺陷</h2><h3 id="产生条件"><a href="#产生条件" class="headerlink" title="产生条件"></a>产生条件</h3><p>以下四个条件，只要一个不满足，死锁就不会产生：</p><ul><li><strong>互斥</strong>：比如需要抢锁</li><li><strong>持有并等待</strong>：线程持有资源（如：锁），又在等待其他资源（如：需要的另一把锁）</li><li><strong>非抢占</strong>：线程获得的资源，不能被抢占</li><li><strong>循环等待</strong>：线程形成环路，环路上每个线程都额外持有一个资源，而这个资源又是下一个线程需要的</li></ul><p>所以我们可以考虑四种策略，每种策略都试图阻止一个条件，从而避免死锁</p><h4 id="预防循环等待"><a href="#预防循环等待" class="headerlink" title="预防循环等待"></a>预防循环等待</h4><p>一个想法是，规定锁的获取必须有顺序。一种顺序叫全序(total ordering)，即全部锁都会按照一定的先后顺序获取，必须先申请锁1，才能申请锁2。然而在复杂的系统中，这可能很难做到，所以可以采用偏序(partial ordering)，仅包含所有锁中的几个锁的关系。</p><h4 id="预防持有等待"><a href="#预防持有等待" class="headerlink" title="预防持有等待"></a>预防持有等待</h4><p>可以原子抢锁来避免，原子地抢多个锁。然而这需要知道所需的全部锁，不适合封装，降低了并发。</p><h4 id="预防非抢占"><a href="#预防非抢占" class="headerlink" title="预防非抢占"></a>预防非抢占</h4><p>我们可以让线程在抢到锁1，抢不到锁2时，主动放出锁1。</p><p>值得注意的是，如果另一个线程的抢锁顺序不同，比如先2后1，可能会导致<strong>活锁</strong>，他们同时抢锁失败，一直循环。</p><p>这种方法的封装性一般，若代码在途中获得其他资源（比如内存），必须也要确保他们被释放。</p><h4 id="预防互斥"><a href="#预防互斥" class="headerlink" title="预防互斥"></a>预防互斥</h4><p>不用锁，而使用硬件支持的原子操作。</p><h3 id="调度"><a href="#调度" class="headerlink" title="调度"></a>调度</h3><p>除了死锁的预防，我们还可以通过调度来避免死锁。让不竞争资源的线程并行运行，竞争的串行。</p><h3 id="检查-恢复"><a href="#检查-恢复" class="headerlink" title="检查&#x2F;恢复"></a>检查&#x2F;恢复</h3><p>允许死锁发生，采用死锁的检测和恢复技术。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Operating System</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>内存虚拟化</title>
    <link href="/2024/08/30/%E5%86%85%E5%AD%98%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    <url>/2024/08/30/%E5%86%85%E5%AD%98%E8%99%9A%E6%8B%9F%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h1 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h1><p>虚拟内存具有以下目标：</p><ul><li>透明：即程序会被欺骗得很好</li><li>效率：在虚拟化时，为了提高效率，需要硬件支持</li><li>保护：确保各个进程的隔离</li></ul><h1 id="地址转换"><a href="#地址转换" class="headerlink" title="地址转换"></a>地址转换</h1><p>先从简单的机制入手（后面会更复杂）</p><h2 id="动态重定位"><a href="#动态重定位" class="headerlink" title="动态重定位"></a>动态重定位</h2><p>基于硬件，最简单的重定位。每个cpu需要加入两个硬件寄存器：<strong>base</strong>和<strong>bound</strong>。当程序执行时，操作系统会决定其基址，设置base寄存器，然后该进程的所有进程引用都会被处理为物理地址：</p><p><code>paddr = vaddr + base</code></p><p>bound寄存器则提供了保护机制，当进程试图越界，会触发异常处理。</p><p>十分明显，这种方法效率低下，进程可能浪费大量内存。</p><h2 id="分段机制"><a href="#分段机制" class="headerlink" title="分段机制"></a>分段机制</h2><p>为了解决上面的问题，我们引入分段的机制。每个段都记录基址，以及界限。则处理地址的过程可以变为：</p><p><code>paddr = bias + base</code></p><p>偏移量可以通过虚拟地址计算出来。可以用虚拟地址的前几位来表示目标段：</p><p><code>[ s1 | s0 | v11 | ... | v0 ]</code></p><p>注意到栈的机制，我们不可以直接用虚拟地址来当偏移量，可以再增加一位用来记录是否反向增长。</p><p>该机制还可以提高保护，比如再引进一位用来记录段的权限。</p><p>物理内存的一个段可以映射到多个虚拟地址空间。</p><p>但该方法无法避免内存碎片，只能减少。需要更好的机制。</p><h1 id="空闲空间管理"><a href="#空闲空间管理" class="headerlink" title="空闲空间管理"></a>空闲空间管理</h1><p>先考虑外部碎片，即由于空闲空间大小不一，导致总空闲空间足够，但因为不连续而导致无法分配。</p><p>主要讲了一些合并与寻找空闲块的策略。</p><h2 id="基本策略"><a href="#基本策略" class="headerlink" title="基本策略"></a>基本策略</h2><ul><li>最优匹配：找候选块最小的可满足的，减少碎片大小</li><li>最差匹配：找候选最大的，留大块碎片（通常糟糕）</li><li>首次匹配：找第一个符合的，速度快</li><li>下次匹配：从上次分配的位置接着往后找</li></ul><h2 id="分离空闲列表"><a href="#分离空闲列表" class="headerlink" title="分离空闲列表"></a>分离空闲列表</h2><p>（不是很理解）</p><h2 id="伙伴系统"><a href="#伙伴系统" class="headerlink" title="伙伴系统"></a>伙伴系统</h2><p>将空闲空间一直二分，直到满足。这样释放的时候，检查伙伴的块，可以实现递归合并。且由于这种机制，一对伙伴之间的地址关系很显然：他们只有一位不同。</p><h1 id="分页"><a href="#分页" class="headerlink" title="分页"></a>分页</h1><p>前面分段的方法，将空间切分成长度不同的部分，造成碎片。我们可以试试将物理内存定长分割，每一块叫做<strong>页</strong>。这种方法抽象程度更高，通过虚拟页与物理页映射，不用考虑进程怎么使用地址。</p><p>通过<strong>页表</strong>，实现虚拟页号（VPN）到物理页号（PFN）的转换。页表记录vpn与pfn的映射关系。比如：<br><code>[vpn|offset] -&gt; [pfn|offset]</code>实际上就完成了地址的转换。</p><h2 id="页表"><a href="#页表" class="headerlink" title="页表"></a>页表</h2><p>在哪？我们可以建立一个<strong>页表基址寄存器</strong>(PTBR)来记录。现在我们可以用伪代码来模拟这个过程：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// extract vpn</span><br>vpn = (vaddr &amp; vpn_mask) &gt;&gt; shift<br><br><span class="hljs-comment">// get pte</span><br>pte_addr = ptbr + vpn * <span class="hljs-keyword">sizeof</span>(pte)<br>pte = M(pte_addr)<br><br><span class="hljs-comment">// check if can process page</span><br><span class="hljs-keyword">if</span>(pte.valid == <span class="hljs-literal">false</span>)<br>error(segmentation fault)<br><span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(pte.ifprotect == <span class="hljs-literal">true</span>)<br>error(protection fault)<br><span class="hljs-keyword">else</span><br>offset = vpn &amp; offset_mask<br>paddr = (pte.pfn &lt;&lt; shift) | offset<br>r = M(paddr)<br></code></pre></td></tr></table></figure><h2 id="TLB"><a href="#TLB" class="headerlink" title="TLB"></a>TLB</h2><p>由学过的储存器层次结构，caching是一种能加速内存访问的技术，应用于页表，就是TLB。TLB将前面的PTE表项拿来作为表项。</p><p>处理未命中时，系统抛出异常，加载更新TLB，再回到指令处重新执行。注意并非下一条指令，与之前讲的中断不一样。同时要注意无限递归，即异常处理程序本身不在TLB中。TLB为全相联的结构，所以可以直接并行查找，速度快。</p><p>因为不同的进程映射关系不同，理论上上下文切换时，应该清空TLB，但这样开销太大，可以考虑为TLB加上地址空间标识符（ASID）</p><p>一些替换策略：</p><ul><li>LRU</li><li>随机：避免上面方法的抖动现象</li></ul><h2 id="更小的页表"><a href="#更小的页表" class="headerlink" title="更小的页表"></a>更小的页表</h2><p>从上面知道，页表的项数为：2的 分配给页表的位数 次方，显然，页表本身为一笔不小的开销。我们思考以下方法：</p><p><strong>更大的页</strong>：通过减少vpn的位数从而减少页表，但内部碎片过大</p><p><strong>分段分页混合</strong>：我们不为整个进程提供页表，只对三个逻辑分段提供。之前每段都有一对基址界限寄存器，现在让基址寄存器记录该段的页表上的位置，界限记录有多少有效页。</p><p><strong>多级页表</strong>：本质就是将之前的页表分成页，用高一级的页表记录。好处是，当有一个<strong>页</strong>的页表项没有记录东西，我们可以在高一级的页表上用有效为0的表项来表示，从而避免给空页表分配空间。如下：</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs coq">[   vpn     |   <span class="hljs-type">offset</span>  ]<br>[ pti | <span class="hljs-type">pfn</span> |   <span class="hljs-type">offset</span>  ]<br>[pd1|<span class="hljs-type">pd0</span>|<span class="hljs-type">pfn</span>|   <span class="hljs-type">offset</span>  ]<br>...<br></code></pre></td></tr></table></figure><h2 id="超越物理内存"><a href="#超越物理内存" class="headerlink" title="超越物理内存"></a>超越物理内存</h2><h3 id="机制"><a href="#机制" class="headerlink" title="机制"></a>机制</h3><p>我们之前都是假设虚拟内存的空间地址小于物理内存的，为了支持运行更多更大的进程需要在内存层级（memory hierarchy）上加层。</p><p>在这里，我们考虑在物理内存下加上硬盘，并在硬盘上开辟交换空间。</p><p>为了支持交换空间，我们需要添加更多机制。比如在页表项添加存在位，表示该页是否在物理内存中。如果不在，会触发<strong>页错误</strong>。触发之后，会通过硬盘的I&#x2F;O来更新页表。注意在I&#x2F;O运行时，进程阻塞，此时可以执行其他进程，就是cpu虚拟化里提到的[[CPU虚拟化#overlap]]</p><p>同时，操作系统并非等到内存满才会交换页，实际上它可以主动预留一小部分内存。设置<strong>高水位线</strong>（HW）和<strong>低水位线</strong>（LW），当操作系统发现少于LW个页可用，会执行后台释放内存的进程直到有HW个页可用。</p><p>还有，通过同时执行多个交换过程，可以提高性能。</p><h3 id="策略"><a href="#策略" class="headerlink" title="策略"></a>策略</h3><p>为了效率，应该思考在页替换时的选择策略。</p><p><strong>最优替换策略</strong>：本质上需要可以预知未来。是一种无法实现，但可以作为参照（用于评估另一种算法好坏）的方法。具体是替换最远将来会访问的页（听着就很科幻）。</p><p><strong>FIFO</strong>：最先进入缓存的页out，缺点是其无法确定页的重要性。</p><p><strong>随机</strong>：看运气，也是不够智能</p><p><strong>LRU</strong>：可以通过历史记录，在执行替换时，踢出最少最近使用的页。</p><p><strong>近似LRU</strong>：LRU因为需要扫描所有页来实现替换，开销太大。以下是一种近似方法。给硬件增加使用位（use bit），每当页被引用时，使用位设置为1。我们采取<strong>时钟算法</strong>，当需要替换时，时钟指针检查当前指向的页的使用位，如果为1，则将其设置为0，并指向下一页，直到遇到使用位为0的页。</p><p>脏页。因为在内存中，一个没有修改过的页显然写回成本要小于修改过的（因为可以直接释放，不用进行I&#x2F;O）。所以可以考虑加一个脏位（dirty bit）。</p><p>还有一些策略：比如<strong>预取</strong>，<strong>聚集写入</strong>等。</p><h2 id="VAX-VMS"><a href="#VAX-VMS" class="headerlink" title="VAX&#x2F;VMS"></a>VAX&#x2F;VMS</h2><p>主要研究该操作系统的一些有意思的虚拟内存管理。</p><h3 id="地址空间"><a href="#地址空间" class="headerlink" title="地址空间"></a>地址空间</h3><p>内核虚拟空间是每个用户地址空间的一部分。在上下文切换时，该段的基址界限寄存器不会变，本质是将相同的地址空间映射到各个用户。</p><h3 id="页替换策略"><a href="#页替换策略" class="headerlink" title="页替换策略"></a>页替换策略</h3><p><strong>分段的FIFO的策略</strong>：每个进程都有一个可以保留在内存中的最大页数（resident set size），当超过RSS时，先入被驱逐。VMS还引入了二次机会列表（second- chance list），分别为一个全局干净列表和脏列表。页在被踢出之前放在这里。</p><p><strong>页聚集</strong>：将大批量的脏页分组到一起，并一举写入磁盘。</p><h3 id="惰性优化"><a href="#惰性优化" class="headerlink" title="惰性优化"></a>惰性优化</h3><p><strong>按需置零</strong>：当用户添加页到堆，（比如malloc），并不直接分配一个置零的页，而是只在页表里放入一个不可访问的条目。当用户需要读取或者写入该页，才会寻找物理页，将其置0并映射到地址空间。而如果进程不访问这页，就直接省去了这个开销。</p><p><strong>写时复制</strong>：若操作系统需要将一个页面从一个地址空间复制到另一个（比如fork），不会实际复制，而是将其映射到目标地址空间并标记为只读。当需要写的时候，才会分配新页填充数据并重新映射。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Operating System</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CPU虚拟化</title>
    <link href="/2024/08/30/CPU%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    <url>/2024/08/30/CPU%E8%99%9A%E6%8B%9F%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h1 id="intro"><a href="#intro" class="headerlink" title="intro"></a>intro</h1><blockquote><p>线程简单理解：一个<strong>进程</strong>里可以有多个线程，线程可以看作小的进程。同一个进程下的线程共享全局变量和堆内存。</p></blockquote><h1 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h1><h2 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h2><p>现代操作系统lazily执行该过程，只有到需要时才会加载数据到进程的地址空间。</p><h3 id="API"><a href="#API" class="headerlink" title="API"></a>API</h3><h4 id="fork"><a href="#fork" class="headerlink" title="fork"></a>fork</h4><p>拷贝父进程，但从fork开始执行。同时fork的返回值，子进程是0，父进程为子进程的pid。</p><h4 id="wait"><a href="#wait" class="headerlink" title="wait"></a>wait</h4><p>延迟进程的执行，直到子进程运行完毕才返回</p><h4 id="exec"><a href="#exec" class="headerlink" title="exec"></a>exec</h4><p>并无创建子进程，而是将当前运行的程序替换为不同的运行程序。通过参数来重新初始化代码段、堆、栈等。</p><p>fork和exec的分开可以实现很多功能。shell：先找到可执行程序，接着fork新进程，在新进程里面exec程序，最后wait直到进程结束。比如shell的重定向。</p><p>如：<code>$ cat hello.c &gt; hello.txt</code>，在运行cat之前，先打开hello.txt，关闭stdout，然后再运行，就可以实现重定向。</p><h1 id="limited-direct-execution"><a href="#limited-direct-execution" class="headerlink" title="limited direct execution"></a>limited direct execution</h1><h2 id="限制操作"><a href="#限制操作" class="headerlink" title="限制操作"></a>限制操作</h2><p>为了让进程可以安全地在cpu上运行，引入不同的模式：</p><ul><li>user mode：行为受限</li><li>kernel mode：可以实现特权操作。<br>执行系统调用时，会通过<strong>trap</strong>来跳入内核并切换模式。通过内核启动时设置的<strong>trap table</strong>来跳转到相应的异常处理代码</li></ul><h2 id="进程切换"><a href="#进程切换" class="headerlink" title="进程切换"></a>进程切换</h2><h3 id="cooperative"><a href="#cooperative" class="headerlink" title="cooperative"></a>cooperative</h3><p>当应用程序结束、异常、运行时间过长，或者通过系统调用，控制权回归操作系统。（理想的程序）</p><h3 id="timer-interrupt"><a href="#timer-interrupt" class="headerlink" title="timer interrupt"></a>timer interrupt</h3><p>时钟为设备产生周期性的中断，控制权还给操作系统，让os决定接下来运行什么。</p><h3 id="context"><a href="#context" class="headerlink" title="context"></a>context</h3><p>保存恢复上下文，即上下文切换。为当前的进程保存状态（寄存器etc），为接下来的进程恢复状态。注意与上文的中断不同，前者隐式保存用户的寄存器到该进程的内核栈，后者显示保存到该进程结构的内存（通过保存指针，来保存和恢复状态）（？）</p><h1 id="进程调度基础"><a href="#进程调度基础" class="headerlink" title="进程调度基础"></a>进程调度基础</h1><h2 id="指标"><a href="#指标" class="headerlink" title="指标"></a>指标</h2><p>对于每个进程：<br>周转时间 &#x3D; 完成时间 - 到达时间 （性能）<br>响应时间 &#x3D; 首次运行时间 - 到达时间（公平）</p><h2 id="SJF"><a href="#SJF" class="headerlink" title="SJF"></a>SJF</h2><p><strong>shortest job first</strong>，先运行最短时间的任务。对比FIFO的工作方式，周转时间降低。</p><h2 id="STCF"><a href="#STCF" class="headerlink" title="STCF"></a>STCF</h2><p><strong>shortest time-to-complete first</strong>，又称抢占式任务优先，每当有新工作加入系统，都会确定哪个工作的剩余时间最小，周转时间降低。</p><h2 id="RR"><a href="#RR" class="headerlink" title="RR"></a>RR</h2><p>轮转调度，将工作变成多个时间切片，循环执行不同工作的切片。时间片变短，响应时间越高，但相对的上下文切换的成本提高。公平和性能是一对需要权衡的因素，不可兼得。</p><h2 id="overlap"><a href="#overlap" class="headerlink" title="overlap"></a>overlap</h2><p>一个工作使用I&#x2F;O的时间，可以看成是独立于该工作。则另一个工作可以利用I&#x2F;O运行的时间。</p><h1 id="MLFQ"><a href="#MLFQ" class="headerlink" title="MLFQ"></a>MLFQ</h1><p><strong>multi-level feedback queue</strong>，多级反馈队列，其维护了多个优先级不同的队列，每个工作只存在于一个队列中，不同的队列有不同的时间配额，利用反馈的信息来决定工作的优先级。下面是其规则：</p><ul><li>A的优先级 &gt; B的优先级，则运行A而不运行B</li><li>A的优先级 &#x3D; B的优先级，则轮转运行A和B</li><li>工作进入系统时，放在最高优先级的队列</li><li>一旦工作用完了其在该队列的时间配额，就降低其优先级</li><li>经过一段时间S，所有工作重新加入最优先队列</li></ul><h1 id="proportional-share"><a href="#proportional-share" class="headerlink" title="proportional-share"></a>proportional-share</h1><p>比例份额调度</p><h2 id="lottery-share"><a href="#lottery-share" class="headerlink" title="lottery share"></a>lottery share</h2><p>进程运行越久，其彩票越多。在每次调度决策之前，都会抽出一个数字（中奖号码），显然，彩票越多的进程，中奖概率越大，则作为下一个运行的对象。该方法运用了随机性，当运行时间足够长时，不同工作的时间比例会趋于期望。实现上，比较轻量。</p><p>和LRU替换算法进行对比，LRU在遇到重复循环序列时，性能低。而彩票调度可以避免。</p><h2 id="stride-scheduling"><a href="#stride-scheduling" class="headerlink" title="stride scheduling"></a>stride scheduling</h2><p>步长调度，算法始终选择行程值最小的工作。严格实现，在每次调度都是正确的比例。</p><p>然而以上两种方法都不常用。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Operating System</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Squeeze Compressor</title>
    <link href="/2024/08/30/Squeeze-Compressor/"/>
    <url>/2024/08/30/Squeeze-Compressor/</url>
    
    <content type="html"><![CDATA[<h2 id="overview"><a href="#overview" class="headerlink" title="overview"></a>overview</h2><p>核心的想法是：对于可精确预测的数据，通过曲线拟合；对于难以合适预测的数据，通过二进制表示的分析来进行有损压缩。</p><h2 id="implement"><a href="#implement" class="headerlink" title="implement"></a>implement</h2><p>压缩前需要的三个参数：绝对误差范围、相对误差范围、压缩率</p><p>以下是压缩的具体算法：</p><h3 id="convert-array"><a href="#convert-array" class="headerlink" title="convert array"></a>convert array</h3><p>通过实验发现，建立曲线是压缩中最大的时间开销。鉴于有<strong>较低的转换开销</strong>、<strong>良好地保留了局部性</strong>的两个优势，使用数据数组原来在内存中的序列用来压缩会更好。</p><h3 id="curve-fitting"><a href="#curve-fitting" class="headerlink" title="curve-fitting"></a>curve-fitting</h3><p>每个数据点都会检查其能否根据先前的数据，使用以下三种曲线近似方法的一种来表示，若可以，易知即可压缩成2bit的数据。</p><ul><li>PNF：通过前一个数据点的<strong>原数据</strong>来预测（01）</li><li>LCF：前两个数据点的<strong>原数据</strong>的线性估计（10）</li><li>QCF：通过前三个数据点的二次曲线来预测（11）</li><li>无法预测：（00）</li></ul><p>该部分会分为以下几步来实现：<br>假设有M个数据点</p><ul><li>分配2Mbits的内存，用于存放压缩后的数据</li><li>计算数据值的变化范围</li><li>检查数据点，决定近似方法，若可近似，将对应的编号写入内存处；若不可近似，则通过对二进制表示的分析来压缩，并写入另一个数组</li></ul><p>由以上的算法，可以看出，该部分的时间复杂度为O(n)，时间和数据量成线性关系十分优秀。</p><h3 id="binary-representation-analysis"><a href="#binary-representation-analysis" class="headerlink" title="binary representation analysis"></a>binary representation analysis</h3><p>以下是二进制表示分析的过程</p><ul><li>通过将所有数据减去中位数，产生<strong>规范化数据</strong>，以缩小数值的范围（可以用更少的位数来表示）</li><li>接着，在误差允许的范围内，抛弃部分影响不大的有效位，再计算需要多少位来表示（注意此处最小的单位为字节，需要将结果约成8的倍数）</li><li>最后，计算需要填充的0的数量，用2bits即可表示（单位为一个全0的字节）</li></ul><h2 id="further-explore"><a href="#further-explore" class="headerlink" title="further explore"></a>further explore</h2><p>SZ压缩提高了数据压缩的速度以及压缩率。可以应用于CPU、GPU、FPGA以及其他科研领域。上文只是SZ的最初实现（SZ 0.1-1.0)的算法。目前SZ以及更新到SZ 3.0了</p><h2 id="citations"><a href="#citations" class="headerlink" title="citations"></a>citations</h2><p>大部分内容来自于以下的论文：</p><ul><li>SZ 0.1-1.0: Sheng Di, Franck Cappello, “<a href="https://ieeexplore.ieee.org/document/7516069">Fast Error-bounded Lossy HPC Data Compression with SZ</a>“, in IEEE International Parallel and Distributed Processing Symposium (IPDPS 2016), Chicago, IL, USA, 2016.</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>research</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>test2</title>
    <link href="/2024/08/30/test2/"/>
    <url>/2024/08/30/test2/</url>
    
    <content type="html"><![CDATA[<h1 id="进行一些简单的测试"><a href="#进行一些简单的测试" class="headerlink" title="进行一些简单的测试"></a>进行一些简单的测试</h1><h2 id="标题测试"><a href="#标题测试" class="headerlink" title="标题测试"></a>标题测试</h2><h1 id="h1"><a href="#h1" class="headerlink" title="h1"></a>h1</h1><h2 id="h2"><a href="#h2" class="headerlink" title="h2"></a>h2</h2><h3 id="h3"><a href="#h3" class="headerlink" title="h3"></a>h3</h3><h4 id="h4"><a href="#h4" class="headerlink" title="h4"></a>h4</h4><h2 id="代码块测试"><a href="#代码块测试" class="headerlink" title="代码块测试"></a>代码块测试</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c">hello, world!<br></code></pre></td></tr></table></figure><h2 id="列表测试"><a href="#列表测试" class="headerlink" title="列表测试"></a>列表测试</h2><ul><li>1</li><li>2</li><li>3</li></ul><h2 id="数学公式"><a href="#数学公式" class="headerlink" title="数学公式"></a>数学公式</h2><p>$$<br>x &#x3D; 1<br>$$</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2024/08/29/hello-world/"/>
    <url>/2024/08/29/hello-world/</url>
    
    <content type="html"><![CDATA[<p>It starts here.</p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
